{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6497bd",
   "metadata": {},
   "source": [
    "# Iterated Prisoner's Dilemma On A Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f664e0b",
   "metadata": {},
   "source": [
    "## Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857538bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from IPython.display import display, HTML, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import os, json, hashlib\n",
    "import re\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from matplotlib.animation import PillowWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams[\"animation.embed_limit\"] = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s - %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7e923",
   "metadata": {},
   "source": [
    "## Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weak_pd_payoff(T, R =1.0, S = 0.0, P=0.0):\n",
    "    return {\n",
    "        (\"C\",\"C\"):(R,R),\n",
    "        (\"C\",\"D\"):(S,T),\n",
    "        (\"D\",\"C\"):(T,S),\n",
    "        (\"D\",\"D\"):(P,P),\n",
    "    }\n",
    "\n",
    "def make_payoff_grid(T_values):\n",
    "    payoff_mats = {}\n",
    "    for T in T_values:\n",
    "        payoff_mats[f\"T={T:.2f}\"] = make_weak_pd_payoff(T=T)\n",
    "    return payoff_mats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684ac16",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Prison import ActionStrategy, ImitationStrategy, FermiStrategy, ReinforcementLearningStrategy, TitForTatStrategy\n",
    "from Prison import Agent, Network, NetworkSimulation\n",
    "from Prison import experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d2424",
   "metadata": {},
   "source": [
    "### Measurement Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60ab107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coop_fraction(actions_dict):\n",
    "    # actions_dict: node -> 'C'/'D'\n",
    "    n = len(actions_dict)\n",
    "    return sum(1 for a in actions_dict.values() if a == \"C\") / n\n",
    "\n",
    "def coop_component_sizes(G, actions_dict):\n",
    "    coop_nodes = [i for i,a in actions_dict.items() if a == \"C\"]\n",
    "    if len(coop_nodes) == 0:\n",
    "        return []\n",
    "    H = G.subgraph(coop_nodes)\n",
    "    return [len(cc) for cc in nx.connected_components(H)]\n",
    "\n",
    "def smax_fraction(G, actions_dict):\n",
    "    sizes = coop_component_sizes(G, actions_dict)\n",
    "    if not sizes:\n",
    "        return 0.0\n",
    "    return max(sizes) / G.number_of_nodes()\n",
    "\n",
    "def add_strategy_short(df, col=\"strategy\"):\n",
    "    def short(s):\n",
    "        s = str(s)\n",
    "        if \"ActionStrategy\" in s: return \"Action\"\n",
    "        if \"ImitationStrategy\" in s: return \"Imitate\"\n",
    "        if \"Fermi\" in s: return \"Fermi\"\n",
    "        if \"RLStrategy\" in s or \"Reinforcement\" in s: return \"RL\"\n",
    "        if \"TitForTat\" in s: return \"TFT\"\n",
    "        return re.sub(r\"\\(.*\\)\", \"\", s)\n",
    "    df = df.copy()\n",
    "    df[\"strategy_short\"] = df[col].astype(str).map(short)\n",
    "    return df\n",
    "\n",
    "def susceptibility_from_sizes(sizes):\n",
    "    \"\"\"\n",
    "    sizes: list of component sizes of cooperative subgraph at time t.\n",
    "    returns chi(t) per your definition; 0.0 if undefined.\n",
    "    \"\"\"\n",
    "    if not sizes:\n",
    "        return 0.0\n",
    "    smax = max(sizes)\n",
    "    counts = Counter(sizes)  # n_s\n",
    "\n",
    "    num = 0.0\n",
    "    den = 0.0\n",
    "    for s, ns in counts.items():\n",
    "        if s == smax:\n",
    "            continue\n",
    "        num += (s**2) * ns\n",
    "        den += s * ns\n",
    "    return (num / den) if den > 0 else 0.0\n",
    "\n",
    "def cluster_size_counts_from_sizes(sizes):\n",
    "    \"\"\"sizes: list[int] -> Counter(size -> count).\"\"\"\n",
    "    return Counter(sizes)\n",
    "\n",
    "def singleton_cooperator_fraction(G, actions_dict):\n",
    "    \"\"\"\n",
    "    fraction of cooperators that are isolated singletons (cluster size = 1).\n",
    "    \"\"\"\n",
    "    sizes = coop_component_sizes(G, actions_dict)\n",
    "    if not sizes:\n",
    "        return 0.0\n",
    "    totalC = sum(sizes)\n",
    "    if totalC == 0:\n",
    "        return 0.0\n",
    "    n_single_clusters = sum(1 for s in sizes if s == 1)\n",
    "    single_C = n_single_clusters * 1\n",
    "    return single_C / totalC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f96cc5",
   "metadata": {},
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9540a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_int(s: str, mod: int = 10_000_000) -> int:\n",
    "    \"\"\"Stable across sessions (unlike Python's built-in hash).\"\"\"\n",
    "    import hashlib\n",
    "    return int(hashlib.md5(str(s).encode(\"utf-8\")).hexdigest()[:8], 16) % mod\n",
    "\n",
    "\n",
    "def normalize_network_spec(net):\n",
    "    \"\"\"\n",
    "    Accept either:\n",
    "      A) dict: {\"name\":..., \"kind\":..., \"n\":..., \"graph_kwargs\": {...}}\n",
    "      B) tuple: (name, dict(kind=..., n=..., ...))\n",
    "    Return dict in form A.\n",
    "    \"\"\"\n",
    "    if isinstance(net, dict):\n",
    "        if \"name\" not in net:\n",
    "            raise ValueError(\"Network dict must include key 'name'.\")\n",
    "        return net\n",
    "\n",
    "    if isinstance(net, tuple) and len(net) == 2 and isinstance(net[1], dict):\n",
    "        name, spec = net\n",
    "        spec = spec.copy()\n",
    "        if \"kind\" not in spec or \"n\" not in spec:\n",
    "            raise ValueError(f\"Network tuple spec must include 'kind' and 'n': {net}\")\n",
    "\n",
    "        kind = spec.pop(\"kind\")\n",
    "        n = spec.pop(\"n\")\n",
    "\n",
    "        graph_kwargs = spec.pop(\"graph_kwargs\", None)\n",
    "        if graph_kwargs is None:\n",
    "            graph_kwargs = spec\n",
    "        else:\n",
    "            merged = dict(spec)\n",
    "            merged.update(graph_kwargs)\n",
    "            graph_kwargs = merged\n",
    "\n",
    "        return {\"name\": name, \"kind\": kind, \"n\": n, \"graph_kwargs\": graph_kwargs}\n",
    "\n",
    "    raise TypeError(f\"Unknown network spec format: {type(net)} -> {net}\")\n",
    "\n",
    "\n",
    "def normalize_strategy_spec(strat):\n",
    "    \"\"\"\n",
    "    Accept either:\n",
    "      A) dict: {\"name\":..., \"cls\": StrategyClass, \"kwargs\": {...}}\n",
    "      B) tuple: (name, StrategyClass) or (name, StrategyClass, kwargs_dict)\n",
    "    Return dict in form A.\n",
    "    \"\"\"\n",
    "    if isinstance(strat, dict):\n",
    "        if \"name\" not in strat or \"cls\" not in strat:\n",
    "            raise ValueError(\"Strategy dict must include keys 'name' and 'cls'.\")\n",
    "        out = strat.copy()\n",
    "        out[\"kwargs\"] = out.get(\"kwargs\", {}) or {}\n",
    "        return out\n",
    "\n",
    "    if isinstance(strat, tuple) and len(strat) in (2, 3):\n",
    "        name = strat[0]\n",
    "        cls = strat[1]\n",
    "        kwargs = strat[2] if len(strat) == 3 else {}\n",
    "        return {\"name\": name, \"cls\": cls, \"kwargs\": kwargs or {}}\n",
    "\n",
    "    raise TypeError(f\"Unknown strategy spec format: {type(strat)} -> {strat}\")\n",
    "\n",
    "\n",
    "def susceptibility_from_sizes(sizes):\n",
    "    \"\"\"\n",
    "    Percolation-style susceptibility:\n",
    "      chi = sum_{s != smax} s^2 n_s / sum_{s != smax} s n_s\n",
    "    where n_s = number of clusters of size s.\n",
    "    \"\"\"\n",
    "    if not sizes:\n",
    "        return 0.0\n",
    "    smax = max(sizes)\n",
    "    counts = Counter(sizes)\n",
    "\n",
    "    num = 0.0\n",
    "    den = 0.0\n",
    "    for s, ns in counts.items():\n",
    "        if s == smax:\n",
    "            continue\n",
    "        num += (s**2) * ns\n",
    "        den += s * ns\n",
    "    return num / den if den > 0 else 0.0\n",
    "\n",
    "\n",
    "def run_one_setting(\n",
    "    net_spec,\n",
    "    strat_spec,\n",
    "    payoff_matrix,\n",
    "    steps=4000,\n",
    "    burn_in=2000,\n",
    "    window=1000,\n",
    "    seed=0,\n",
    "    sample_cluster_every=50,\n",
    "    sanity_check=False,\n",
    "    record_window_sizes=True,\n",
    "    record_samples=True,\n",
    "    max_samples=200,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns per-run summary + recorded cluster sizes.\n",
    "\n",
    "    record_window_sizes:\n",
    "      - if True, store ALL cluster sizes sampled within the averaging window\n",
    "        (best for histogram/CCDF evidence).\n",
    "\n",
    "    record_samples:\n",
    "      - if True, store time-stamped samples (t, sizes), capped by max_samples\n",
    "        (best for \"see evolution\" / debugging).\n",
    "    \"\"\"\n",
    "    net_spec = normalize_network_spec(net_spec)\n",
    "    strat_spec = normalize_strategy_spec(strat_spec)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    sim = NetworkSimulation(\n",
    "        kind=net_spec[\"kind\"],\n",
    "        n=net_spec[\"n\"],\n",
    "        seed=seed,\n",
    "        rounds=0,\n",
    "        strategy=strat_spec[\"cls\"],\n",
    "        strategy_kwargs=strat_spec.get(\"kwargs\", {}) or {},\n",
    "        payoff_matrix=payoff_matrix,\n",
    "        rng=rng,\n",
    "        store_snapshots=False,\n",
    "        **(net_spec.get(\"graph_kwargs\", {}) or {}),\n",
    "    )\n",
    "\n",
    "    G = sim.graph\n",
    "    N = G.number_of_nodes()\n",
    "\n",
    "    C_series = []\n",
    "    Smax_series = []\n",
    "    Chi_series = []\n",
    "\n",
    "    # NEW: store sizes for window hist/ccdf evidence\n",
    "    window_sizes_all = []  # flattened list of all sampled cluster sizes in window\n",
    "\n",
    "    # NEW: optional time-stamped samples (limited)\n",
    "    cluster_samples = []\n",
    "    samples_kept = 0\n",
    "\n",
    "    absorbed = False\n",
    "    absorb_state = None\n",
    "    t_absorb = None\n",
    "\n",
    "    for t in range(steps):\n",
    "        sim.step()\n",
    "        actions = {node: agent.strategy.action for node, agent in sim.agents.items()}\n",
    "        Ct = coop_fraction(actions)\n",
    "        C_series.append(Ct)\n",
    "\n",
    "        # absorption\n",
    "        if Ct == 1.0:\n",
    "            absorbed, absorb_state, t_absorb = True, \"allC\", t + 1\n",
    "            break\n",
    "        if Ct == 0.0:\n",
    "            absorbed, absorb_state, t_absorb = True, \"allD\", t + 1\n",
    "            break\n",
    "\n",
    "        # sample clusters (if enabled)\n",
    "        do_sample = (sample_cluster_every is not None) and (sample_cluster_every > 0) and ((t % sample_cluster_every) == 0)\n",
    "        if do_sample:\n",
    "            sizes = coop_component_sizes(G, actions)\n",
    "\n",
    "            # Optional time-stamped samples for evolution\n",
    "            if record_samples and (samples_kept < max_samples):\n",
    "                cluster_samples.append({\"t\": t + 1, \"sizes\": sizes})\n",
    "                samples_kept += 1\n",
    "\n",
    "            # Only accumulate window evidence/stats in [burn_in, burn_in+window)\n",
    "            if burn_in <= t < (burn_in + window):\n",
    "                if record_window_sizes:\n",
    "                    window_sizes_all.extend(sizes)  # flatten\n",
    "                Chi_series.append(susceptibility_from_sizes(sizes))\n",
    "\n",
    "        # Smax in window (cheap, uses sizes via helper)\n",
    "        if burn_in <= t < (burn_in + window):\n",
    "            Smax_series.append(smax_fraction(G, actions))\n",
    "\n",
    "    C_series = np.asarray(C_series, dtype=float)\n",
    "\n",
    "    # barC over window (clip if ended early)\n",
    "    start = burn_in\n",
    "    end = min(len(C_series), burn_in + window)\n",
    "    barC = float(np.mean(C_series[start:end])) if end > start else float(np.mean(C_series))\n",
    "\n",
    "    smax_bar = float(np.mean(Smax_series)) if len(Smax_series) > 0 else np.nan\n",
    "    chi_bar  = float(np.mean(Chi_series)) if len(Chi_series) > 0 else np.nan\n",
    "\n",
    "    if not absorbed:\n",
    "        t_absorb = steps\n",
    "        absorb_state = None\n",
    "\n",
    "    return {\n",
    "        \"barC\": barC,\n",
    "        \"smax_bar\": smax_bar,\n",
    "        \"chi_bar\": chi_bar,\n",
    "        \"absorbed\": absorbed,\n",
    "        \"absorb_state\": absorb_state,\n",
    "        \"t_absorb\": int(t_absorb),\n",
    "        \"n_steps_executed\": int(len(C_series)),\n",
    "        \"cluster_samples\": cluster_samples,  # time-stamped (small, capped)\n",
    "        \"window_sizes_all\": window_sizes_all,  # flattened sizes within window (for hist/ccdf)\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) evaluate_revised_plan: saves BOTH samples + window sizes\n",
    "# ============================================================\n",
    "def evaluate_revised_plan(\n",
    "    networks,\n",
    "    strategies,\n",
    "    payoff_mats,\n",
    "    runs=20,\n",
    "    steps=4000,\n",
    "    burn_in=2000,\n",
    "    window=1000,\n",
    "    seed0=2026,\n",
    "    outdir=\"Result_RQ0/Result_Revised\",\n",
    "    save=True,\n",
    "    sample_cluster_every=50,\n",
    "    record_window_sizes=True,\n",
    "    record_samples=True,\n",
    "    max_samples=200,\n",
    "):\n",
    "    \"\"\"\n",
    "    networks: list of dicts OR list of (name, dict(...))\n",
    "    strategies: list of dicts OR list of (name, cls) / (name, cls, kwargs)\n",
    "    payoff_mats: dict payoff_name -> payoff_matrix\n",
    "\n",
    "    Stores per-run:\n",
    "      - cluster_samples_json: time-stamped samples (capped)\n",
    "      - cluster_sizes_window_json: flattened sizes within averaging window (for distribution evidence)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for payoff_name, payoff_mat in payoff_mats.items():\n",
    "        for net_raw in networks:\n",
    "            net = normalize_network_spec(net_raw)\n",
    "\n",
    "            for strat_raw in strategies:\n",
    "                strat = normalize_strategy_spec(strat_raw)\n",
    "\n",
    "                for r in range(runs):\n",
    "                    seed_run = (\n",
    "                        seed0\n",
    "                        + 100000 * r\n",
    "                        + 1000 * stable_int(payoff_name)\n",
    "                        + 10 * stable_int(net[\"name\"])\n",
    "                        + stable_int(strat[\"name\"])\n",
    "                    )\n",
    "\n",
    "                    res = run_one_setting(\n",
    "                        net_spec=net,\n",
    "                        strat_spec=strat,\n",
    "                        payoff_matrix=payoff_mat,\n",
    "                        steps=steps,\n",
    "                        burn_in=burn_in,\n",
    "                        window=window,\n",
    "                        seed=seed_run,\n",
    "                        sample_cluster_every=sample_cluster_every,\n",
    "                        sanity_check=False,\n",
    "                        record_window_sizes=record_window_sizes,\n",
    "                        record_samples=record_samples,\n",
    "                        max_samples=max_samples,\n",
    "                    )\n",
    "\n",
    "                    rows.append({\n",
    "                        \"payoff\": payoff_name,\n",
    "                        \"network\": net[\"name\"],\n",
    "                        \"strategy\": strat[\"name\"],\n",
    "\n",
    "                        \"barC\": res[\"barC\"],\n",
    "                        \"chi_bar\": res[\"chi_bar\"],\n",
    "                        \"smax_bar\": res[\"smax_bar\"],\n",
    "\n",
    "                        \"absorbed\": res[\"absorbed\"],\n",
    "                        \"absorb_state\": res[\"absorb_state\"],\n",
    "                        \"t_absorb\": res[\"t_absorb\"],\n",
    "                        \"n_steps_executed\": res[\"n_steps_executed\"],\n",
    "\n",
    "                        \"cluster_samples_json\": json.dumps(res[\"cluster_samples\"]),\n",
    "                        \"cluster_sizes_window_json\": json.dumps(res[\"window_sizes_all\"]),\n",
    "                    })\n",
    "\n",
    "    per_run_df = pd.DataFrame(rows)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        per_run_df = add_strategy_short(per_run_df, col=\"strategy\")\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "    def pr_allC(x): return float(np.mean(x == \"allC\"))\n",
    "    def pr_allD(x): return float(np.mean(x == \"allD\"))\n",
    "\n",
    "    group_cols = [\"payoff\", \"network\", \"strategy\"]\n",
    "    if \"strategy_short\" in per_run_df.columns:\n",
    "        group_cols.append(\"strategy_short\")\n",
    "\n",
    "    summary_df = (\n",
    "        per_run_df.groupby(group_cols, as_index=False)\n",
    "        .agg(\n",
    "            mean_barC=(\"barC\", \"mean\"),\n",
    "            std_barC=(\"barC\", \"std\"),\n",
    "\n",
    "            mean_smax=(\"smax_bar\", \"mean\"),\n",
    "            std_smax=(\"smax_bar\", \"std\"),\n",
    "\n",
    "            mean_chi=(\"chi_bar\", \"mean\"),\n",
    "            std_chi=(\"chi_bar\", \"std\"),\n",
    "\n",
    "            Pr_allC=(\"absorb_state\", pr_allC),\n",
    "            Pr_allD=(\"absorb_state\", pr_allD),\n",
    "\n",
    "            mean_t_absorb=(\"t_absorb\", \"mean\"),\n",
    "            std_t_absorb=(\"t_absorb\", \"std\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    per_run_path = None\n",
    "    summ_path = None\n",
    "    if save:\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        per_run_path = os.path.join(outdir, \"per_run_revised.csv\")\n",
    "        summ_path = os.path.join(outdir, \"summary_revised.csv\")\n",
    "        per_run_df.to_csv(per_run_path, index=False)\n",
    "        summary_df.to_csv(summ_path, index=False)\n",
    "\n",
    "    return per_run_df, summary_df, per_run_path, summ_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "networks_revised = [\n",
    "    (\"Grid_20x20\", dict(kind=\"grid\", n=400, graph_kwargs={\"periodic\": False})),\n",
    "    (\"ER_p0.02\",   dict(kind=\"erdos_renyi\", n=400, p=0.02)),  \n",
    "    (\"WS_k8_p0.05\",dict(kind=\"watts_strogatz\", n=400, k=8, p=0.05)), \n",
    "    (\"WS_k8_p0.1\",dict(kind=\"watts_strogatz\", n=400, k=8, p=0.1)), \n",
    "    (\"WS_k8_p0.5\",dict(kind=\"watts_strogatz\", n=400, k=8, p=0.5)), \n",
    "\n",
    "]\n",
    "\n",
    "strategies_revised = [\n",
    "    (\"ImitationStrategy\", ImitationStrategy),\n",
    "    (\"TitForTatStrategy\", TitForTatStrategy),\n",
    "]\n",
    "\n",
    "T_values = np.linspace(1.00, 2.00, 21)\n",
    "payoff_mats_revised = make_payoff_grid(T_values)\n",
    "\n",
    "per_run_revised, summary_revised, per_run_path, summ_path = evaluate_revised_plan(\n",
    "    networks=networks_revised,\n",
    "    strategies=strategies_revised,\n",
    "    payoff_mats=payoff_mats_revised,\n",
    "    runs=15,\n",
    "    steps=2000,\n",
    "    burn_in=1000,\n",
    "    window=1000,\n",
    "    seed0=2026,\n",
    "    outdir=\"Result_RQ0/Result_Revised\",\n",
    "    save=True,\n",
    ")\n",
    "\n",
    "print(\"Saved:\", per_run_path)\n",
    "print(\"Saved:\", summ_path)\n",
    "\n",
    "summary_revised.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4aec75",
   "metadata": {},
   "source": [
    "### Find Tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_T(payoff_name: str) -> float:\n",
    "    m = re.search(r\"([0-9]+(?:\\.[0-9]+)?)\", str(payoff_name))\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse T from payoff name: {payoff_name}\")\n",
    "    return float(m.group(1))\n",
    "\n",
    "\n",
    "def estimate_Tc_from_curve(T, y, method=\"peak\"):\n",
    "    \"\"\"\n",
    "    T: 1D array sorted ascending\n",
    "    y: 1D array same length (may contain nan)\n",
    "    \"\"\"\n",
    "    T = np.asarray(T, float)\n",
    "    y = np.asarray(y, float)\n",
    "\n",
    "    ok = np.isfinite(T) & np.isfinite(y)\n",
    "    T = T[ok]; y = y[ok]\n",
    "    if len(T) < 3:\n",
    "        return np.nan\n",
    "\n",
    "    order = np.argsort(T)\n",
    "    T = T[order]; y = y[order]\n",
    "\n",
    "    if method == \"peak\":\n",
    "        return float(T[np.nanargmax(y)])\n",
    "\n",
    "    if method == \"inflection_slope\":\n",
    "        # discrete derivative, pick largest slope location\n",
    "        dy = np.diff(y) / np.diff(T)\n",
    "        k = int(np.nanargmax(dy))\n",
    "        # Tc between T[k] and T[k+1]\n",
    "        return float(0.5 * (T[k] + T[k+1]))\n",
    "\n",
    "    if method.startswith(\"threshold:\"):\n",
    "        thr = float(method.split(\":\", 1)[1])\n",
    "        idx = np.where(y >= thr)[0]\n",
    "        return float(T[idx[0]]) if len(idx) else np.nan\n",
    "\n",
    "    raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "def find_Tc_table(summary_df):\n",
    "    df = summary_df.copy()\n",
    "    df[\"T\"] = df[\"payoff\"].map(extract_beta) # change T / beta\n",
    "\n",
    "    out = []\n",
    "    for (net, strat), g in df.groupby([\"network\", \"strategy\"]):\n",
    "        g = g.sort_values(\"T\")\n",
    "        T = g[\"T\"].to_numpy()\n",
    "\n",
    "        Tc_peak_chi = estimate_Tc_from_curve(T, g[\"mean_chi\"].to_numpy(), method=\"peak\")\n",
    "        Tc_inflect  = estimate_Tc_from_curve(T, g[\"mean_smax\"].to_numpy(), method=\"inflection_slope\")\n",
    "        \n",
    "\n",
    "        # choose thresholds you like (example)\n",
    "        Tc_thr_C    = estimate_Tc_from_curve(T, g[\"mean_barC\"].to_numpy(), method=\"threshold:0.5\")\n",
    "        Tc_thr_Smax = estimate_Tc_from_curve(T, g[\"mean_smax\"].to_numpy(), method=\"threshold:0.2\")\n",
    "\n",
    "        out.append({\n",
    "            \"network\": net,\n",
    "            \"strategy\": strat,\n",
    "            \"Tc_peak_chi\": Tc_peak_chi,\n",
    "            \"Tc_inflect_smax\": Tc_inflect,\n",
    "            \"Tc_C>=0.5\": Tc_thr_C,\n",
    "            \"Tc_Smax>=0.2\": Tc_thr_Smax,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f094fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tc_df = find_Tc_table(summary_revised)\n",
    "Tc_df.to_csv(\"Result_RQ0/Result_revised/Tc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff659d",
   "metadata": {},
   "source": [
    "### b/c = beta * k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Prison import PayoffMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# V2 — b/c = beta * <k> sweep (keep classes unchanged)\n",
    "# =========================\n",
    "\n",
    "# -------------------------\n",
    "# 1) Revised networks (target <k> = 4)\n",
    "# -------------------------\n",
    "n_nodes = 400\n",
    "kbar_target = 4.0\n",
    "\n",
    "networks_revised = [\n",
    "    # Grid: interior degree=4, boundary smaller (so avg degree slightly < 4 if periodic=False)\n",
    "    (\"Grid_20x20\", dict(kind=\"grid\", n=n_nodes, graph_kwargs={\"periodic\": False})),\n",
    "\n",
    "    # ER: choose p so E[k] ~ p*(n-1) = 4\n",
    "    (\"ER_k4\", dict(kind=\"erdos_renyi\", n=n_nodes, graph_kwargs={\"p\": kbar_target / (n_nodes - 1)})),\n",
    "\n",
    "    # WS: ring lattice degree k=4, then rewire with some p\n",
    "    (\"WS_k4_p0.05\", dict(kind=\"watts_strogatz\", n=n_nodes, graph_kwargs={\"k\": 4, \"p\": 0.05})),\n",
    "    (\"WS_k4_p0.1\", dict(kind=\"watts_strogatz\", n=n_nodes, graph_kwargs={\"k\": 4, \"p\": 0.1})),\n",
    "]\n",
    "\n",
    "strategies_revised = [\n",
    "    (\"ImitationStrategy\", ImitationStrategy),\n",
    "    (\"TitForTatStrategy\", TitForTatStrategy),\n",
    "]\n",
    "\n",
    "# your requested beta series (edit as you like)\n",
    "beta_values = [0.5, 0.8, 1.0, 1.2, 1.5, 2.0, 2.5]\n",
    "\n",
    "payoff_revised = PayoffMatrix(beta_values=beta_values, kbar=kbar_target, c=1.0)\n",
    "# payoff_mats_revised, payoff_meta = payoff_revised.matrices, payoff_revised.meta\n",
    "\n",
    "# Optional: save meta for later plotting/traceability\n",
    "outdir = \"Result_RQ0/Result_Revised_beta\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "payoff_meta_path = os.path.join(outdir, \"payoff_meta_beta.csv\")\n",
    "payoff_revised.meta.to_csv(payoff_meta_path, index=False)\n",
    "print(\"Saved payoff meta:\", payoff_meta_path)\n",
    "\n",
    "# -------------------------\n",
    "# 3) Run experiments\n",
    "# -------------------------\n",
    "per_run_revised, summary_revised, per_run_path, summ_path = evaluate_revised_plan(\n",
    "    networks=networks_revised,\n",
    "    strategies=strategies_revised,\n",
    "    payoff_mats=payoff_revised.matrices,\n",
    "    runs=20,\n",
    "    steps=4000,\n",
    "    burn_in=2000,\n",
    "    window=1000,\n",
    "    seed0=2026,\n",
    "    outdir=outdir,\n",
    "    save=True,\n",
    ")\n",
    "\n",
    "print(\"Saved:\", per_run_path)\n",
    "print(\"Saved:\", summ_path)\n",
    "\n",
    "summary_revised.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1cbbc",
   "metadata": {},
   "source": [
    "### Finding Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Complete code: estimate critical beta (beta_c) from your sweep\n",
    "# Uses:\n",
    "#   - peak of mean_chi(beta)\n",
    "#   - inflection (max slope) of mean_smax(beta)\n",
    "#   - midpoint of mean_smax(beta)\n",
    "#   - threshold crossing of mean_barC or mean_smax(beta)\n",
    "# Works with your existing summary_revised.csv OR summary_revised DataFrame\n",
    "# ============================================================\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Helpers\n",
    "# ----------------------------\n",
    "def extract_beta(payoff_name: str) -> float:\n",
    "    \"\"\"\n",
    "    payoff_name like 'beta_0.50' or 'beta_1.20' -> 0.50, 1.20\n",
    "    \"\"\"\n",
    "    m = re.search(r\"([0-9]+(?:\\.[0-9]+)?)\", str(payoff_name))\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse beta from payoff name: {payoff_name}\")\n",
    "    return float(m.group(1))\n",
    "\n",
    "\n",
    "def smooth_1d(y: np.ndarray, window: int = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simple moving average smoothing. window must be odd.\n",
    "    If window <= 1, returns y unchanged.\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if window is None or window <= 1:\n",
    "        return y\n",
    "    if window % 2 == 0:\n",
    "        window += 1\n",
    "    k = window // 2\n",
    "    ypad = np.pad(y, (k, k), mode=\"edge\")\n",
    "    kernel = np.ones(window, dtype=float) / window\n",
    "    return np.convolve(ypad, kernel, mode=\"valid\")\n",
    "\n",
    "\n",
    "def first_crossing_x(x: np.ndarray, y: np.ndarray, thr: float):\n",
    "    \"\"\"\n",
    "    Return x where y crosses thr (linear interpolation).\n",
    "    If never crosses, return np.nan.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if len(x) < 2:\n",
    "        return np.nan\n",
    "\n",
    "    s = y - thr\n",
    "    for i in range(len(s) - 1):\n",
    "        if (s[i] == 0):\n",
    "            return float(x[i])\n",
    "        if (s[i] < 0 and s[i + 1] > 0) or (s[i] > 0 and s[i + 1] < 0):\n",
    "            # linear interpolation between i and i+1\n",
    "            x0, x1 = x[i], x[i + 1]\n",
    "            y0, y1 = s[i], s[i + 1]\n",
    "            if y1 == y0:\n",
    "                return float(x0)\n",
    "            return float(x0 + (0 - y0) * (x1 - x0) / (y1 - y0))\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def argmax_x(x: np.ndarray, y: np.ndarray):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if len(x) == 0:\n",
    "        return np.nan\n",
    "    return float(x[int(np.nanargmax(y))])\n",
    "\n",
    "\n",
    "def inflection_x(x: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Estimate inflection as location of maximum absolute slope (finite difference).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if len(x) < 3:\n",
    "        return np.nan\n",
    "    dy = np.gradient(y, x)\n",
    "    idx = int(np.nanargmax(np.abs(dy)))\n",
    "    return float(x[idx])\n",
    "\n",
    "\n",
    "def midpoint_x(x: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Midpoint defined as crossing of (min(y)+max(y))/2.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if len(x) < 2:\n",
    "        return np.nan\n",
    "    y_min = np.nanmin(y)\n",
    "    y_max = np.nanmax(y)\n",
    "    mid = 0.5 * (y_min + y_max)\n",
    "    return first_crossing_x(x, y, mid)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Core: estimate beta_c from one curve group\n",
    "# ----------------------------\n",
    "def estimate_beta_c_from_curves(\n",
    "    beta: np.ndarray,\n",
    "    mean_chi: np.ndarray,\n",
    "    mean_smax: np.ndarray,\n",
    "    mean_barC: np.ndarray = None,\n",
    "    smooth_window: int = 3,\n",
    "    thr_C: float = 0.5,\n",
    "    thr_Smax: float = 0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a dict of beta_c estimates using multiple criteria.\n",
    "    \"\"\"\n",
    "\n",
    "    beta = np.asarray(beta, dtype=float)\n",
    "    chi = np.asarray(mean_chi, dtype=float)\n",
    "    smax = np.asarray(mean_smax, dtype=float)\n",
    "\n",
    "    # sort by beta\n",
    "    order = np.argsort(beta)\n",
    "    beta = beta[order]\n",
    "    chi = chi[order]\n",
    "    smax = smax[order]\n",
    "\n",
    "    # optional barC\n",
    "    if mean_barC is not None:\n",
    "        barC = np.asarray(mean_barC, dtype=float)[order]\n",
    "    else:\n",
    "        barC = None\n",
    "\n",
    "    # smooth (helps with noisy peak/derivative)\n",
    "    chi_s = smooth_1d(chi, window=smooth_window)\n",
    "    smax_s = smooth_1d(smax, window=smooth_window)\n",
    "    barC_s = smooth_1d(barC, window=smooth_window) if barC is not None else None\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    # 1) peak of chi\n",
    "    out[\"beta_c_peak_chi\"] = argmax_x(beta, chi_s)\n",
    "\n",
    "    # 2) inflection (max slope) of smax\n",
    "    out[\"beta_c_inflect_smax\"] = inflection_x(beta, smax_s)\n",
    "\n",
    "    # 3) midpoint crossing of smax\n",
    "    out[\"beta_c_mid_smax\"] = midpoint_x(beta, smax_s)\n",
    "\n",
    "    # 4) threshold crossings (user-chosen)\n",
    "    if barC_s is not None:\n",
    "        out[\"beta_c_thr_C\"] = first_crossing_x(beta, barC_s, thr_C)\n",
    "    else:\n",
    "        out[\"beta_c_thr_C\"] = np.nan\n",
    "\n",
    "    out[\"beta_c_thr_Smax\"] = first_crossing_x(beta, smax_s, thr_Smax)\n",
    "\n",
    "    # include some diagnostics\n",
    "    out[\"beta_min\"] = float(np.min(beta)) if len(beta) else np.nan\n",
    "    out[\"beta_max\"] = float(np.max(beta)) if len(beta) else np.nan\n",
    "    out[\"chi_peak\"] = float(np.nanmax(chi_s)) if len(beta) else np.nan\n",
    "    out[\"smax_min\"] = float(np.nanmin(smax_s)) if len(beta) else np.nan\n",
    "    out[\"smax_max\"] = float(np.nanmax(smax_s)) if len(beta) else np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Main: compute beta_c table from summary_revised\n",
    "# ----------------------------\n",
    "def compute_beta_c_table(\n",
    "    summary_df: pd.DataFrame,\n",
    "    group_cols=(\"network\", \"strategy\"),\n",
    "    payoff_col=\"payoff\",\n",
    "    mean_chi_col=\"mean_chi\",\n",
    "    mean_smax_col=\"mean_smax\",\n",
    "    mean_barC_col=\"mean_barC\",\n",
    "    smooth_window=3,\n",
    "    thr_C=0.5,\n",
    "    thr_Smax=0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    summary_df must have:\n",
    "      payoff (e.g., 'beta_0.50')\n",
    "      mean_chi, mean_smax (and optionally mean_barC)\n",
    "      plus grouping columns like network, strategy.\n",
    "    \"\"\"\n",
    "\n",
    "    df = summary_df.copy()\n",
    "\n",
    "    # parse beta from payoff name\n",
    "    df[\"beta\"] = df[payoff_col].map(extract_beta)\n",
    "\n",
    "    # sanity: ensure required cols exist\n",
    "    for c in [mean_chi_col, mean_smax_col]:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"summary_df missing required column: {c}\")\n",
    "\n",
    "    have_barC = mean_barC_col in df.columns\n",
    "\n",
    "    rows = []\n",
    "    for keys, g in df.groupby(list(group_cols), dropna=False):\n",
    "        if not isinstance(keys, tuple):\n",
    "            keys = (keys,)\n",
    "\n",
    "        beta = g[\"beta\"].to_numpy()\n",
    "        mean_chi = g[mean_chi_col].to_numpy()\n",
    "        mean_smax = g[mean_smax_col].to_numpy()\n",
    "        mean_barC = g[mean_barC_col].to_numpy() if have_barC else None\n",
    "\n",
    "        est = estimate_beta_c_from_curves(\n",
    "            beta=beta,\n",
    "            mean_chi=mean_chi,\n",
    "            mean_smax=mean_smax,\n",
    "            mean_barC=mean_barC,\n",
    "            smooth_window=smooth_window,\n",
    "            thr_C=thr_C,\n",
    "            thr_Smax=thr_Smax,\n",
    "        )\n",
    "\n",
    "        row = {col: val for col, val in zip(group_cols, keys)}\n",
    "        row.update(est)\n",
    "        rows.append(row)\n",
    "\n",
    "    out = pd.DataFrame(rows).sort_values(list(group_cols)).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Example usage\n",
    "# ----------------------------\n",
    "# Option A: if you already have summary_revised in memory, just run:\n",
    "# beta_c_df = compute_beta_c_table(summary_revised, group_cols=(\"network\", \"strategy\"))\n",
    "\n",
    "# Option B: load from CSV:\n",
    "# summary_revised = pd.read_csv(\"Result_RQ0/Result_Revised_beta/summary_revised.csv\")\n",
    "\n",
    "# ---- RUN THIS ----\n",
    "beta_c_df = compute_beta_c_table(\n",
    "    summary_revised,                    # <-- your summary dataframe in memory\n",
    "    group_cols=(\"network\", \"strategy\"), # or (\"network\",\"strategy_short\") if you prefer\n",
    "    payoff_col=\"payoff\",\n",
    "    mean_chi_col=\"mean_chi\",\n",
    "    mean_smax_col=\"mean_smax\",\n",
    "    mean_barC_col=\"mean_barC\",\n",
    "    smooth_window=3,\n",
    "    thr_C=0.5,\n",
    "    thr_Smax=0.2,\n",
    ")\n",
    "\n",
    "beta_c_df.to_csv(\"Result_RQ0/Result_Revised_beta/beta_c.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b3d25",
   "metadata": {},
   "source": [
    "### Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGDIR = Path(\"Result_RQ0/Figures_Revised\")\n",
    "FIGDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def show_saved(fig, fname, dpi=200, close=True):\n",
    "    \"\"\"\n",
    "    Option A: savefig + display image file (robust in VS Code notebooks).\n",
    "    \"\"\"\n",
    "    path = FIGDIR / fname\n",
    "    fig.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    if close:\n",
    "        plt.close(fig)\n",
    "    display(Image(filename=str(path)))\n",
    "    return str(path)\n",
    "\n",
    "# =========================\n",
    "# 1) Load data\n",
    "# =========================\n",
    "### for Tc\n",
    "#summary = pd.read_csv(\"Result_RQ0/Result_S1/Result_Revised/summary_revised.csv\")\n",
    "#per_run = pd.read_csv(\"Result_RQ0/Result_S1/Result_Revised/per_run_revised.csv\")\n",
    "#tc = pd.read_csv(\"Result_RQ0/Result_S1/Result_Revised/Tc.csv\")\n",
    "\n",
    "### for Beta\n",
    "summary = pd.read_csv(\"Result_RQ0/Result_Revised_beta/summary_revised.csv\")\n",
    "per_run = pd.read_csv(\"Result_RQ0/Result_Revised_beta/per_run_revised.csv\")\n",
    "meta = pd.read_csv(\"Result_RQ0/Result_Revised_beta/payoff_meta_beta.csv\")\n",
    "tc   = pd.read_csv(\"Result_RQ0/Result_Revised_beta/beta_c.csv\")\n",
    "\n",
    "    \n",
    "# -------------------------\n",
    "# 2) Parse T from payoff name\n",
    "# -------------------------\n",
    "#def parse_T(payoff_str):\n",
    "#    \"\"\"\n",
    "#    Extract first float-like number from the payoff string.\n",
    "#    Works for names like: \"T=1.20\", \"T_1.2\", \"1.2\", \"Temptation=1.2\", etc.\n",
    "#    \"\"\"\n",
    "#   s = str(payoff_str)\n",
    "#   m = re.search(r\"(\\d+(\\.\\d+)?)\", s)\n",
    "#   return float(m.group(1)) if m else np.nan\n",
    "\n",
    "#for df in (summary, per_run, tc):\n",
    "#    if \"payoff\" in df.columns:\n",
    "#        df[\"T\"] = df[\"payoff\"].map(parse_T)\n",
    "#   elif \"T\" not in df.columns:\n",
    "#       # if Tc.csv already has T columns only, leave it\n",
    "#       pass\n",
    "## Ensure sorting\n",
    "#summary = summary.sort_values([\"strategy\", \"network\", \"T\"]).reset_index(drop=True)\n",
    "#per_run = per_run.sort_values([\"strategy\", \"network\", \"T\"]).reset_index(drop=True)\n",
    "\n",
    "# -------------------------\n",
    "# 2) Map beta from payoff name using payoff_meta_beta.csv\n",
    "# -------------------------\n",
    "payoff_to_beta = dict(zip(meta[\"payoff\"], meta[\"beta\"]))\n",
    "\n",
    "for df in (summary, per_run):\n",
    "    df[\"T\"] = df[\"payoff\"].map(payoff_to_beta)  # keep column name \"T\" so your code doesn't change\n",
    "\n",
    "summary = summary.sort_values([\"strategy\", \"network\", \"T\"]).reset_index(drop=True)\n",
    "per_run = per_run.sort_values([\"strategy\", \"network\", \"T\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Small helpers\n",
    "# =========================\n",
    "def short_strategy(name):\n",
    "    s = str(name)\n",
    "    if \"TitForTat\" in s or \"Tit For Tat\" in s:\n",
    "        return \"TFT\"\n",
    "    if \"Imitation\" in s:\n",
    "        return \"Imitate\"\n",
    "    return s\n",
    "\n",
    "summary[\"strategy_short\"] = summary[\"strategy\"].map(short_strategy) if \"strategy\" in summary else \"Strategy\"\n",
    "per_run[\"strategy_short\"] = per_run[\"strategy\"].map(short_strategy) if \"strategy\" in per_run else \"Strategy\"\n",
    "\n",
    "def unique_levels(df, col):\n",
    "    return [x for x in df[col].dropna().unique().tolist()]\n",
    "\n",
    "strategies = unique_levels(summary, \"strategy\") if \"strategy\" in summary else unique_levels(per_run, \"strategy\")\n",
    "networks = unique_levels(summary, \"network\") if \"network\" in summary else unique_levels(per_run, \"network\")\n",
    "\n",
    "# =========================\n",
    "# 4) Core plots (phase curves)\n",
    "# =========================\n",
    "def plot_barC_by_T(summary_df, networks=None, strategies=None):\n",
    "    \"\"\"\n",
    "    mean_barC(T) with error bars (std_barC) for each network, one panel per strategy.\n",
    "    \"\"\"\n",
    "    networks = networks or unique_levels(summary_df, \"network\")\n",
    "    strategies = strategies or unique_levels(summary_df, \"strategy\")\n",
    "\n",
    "    for strat in strategies:\n",
    "        sub = summary_df[summary_df[\"strategy\"] == strat].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # Create one row of subplots (one per network)\n",
    "        ncols = len(networks)\n",
    "        fig, axes = plt.subplots(1, ncols, figsize=(4*ncols, 3), sharey=True)\n",
    "        if ncols == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for ax, net in zip(axes, networks):\n",
    "            tmp = sub[sub[\"network\"] == net].sort_values(\"T\")\n",
    "            if tmp.empty:\n",
    "                ax.set_title(net + \" (no data)\")\n",
    "                continue\n",
    "\n",
    "            x = tmp[\"T\"].to_numpy()\n",
    "            y = tmp[\"mean_barC\"].to_numpy()\n",
    "            yerr = tmp[\"std_barC\"].to_numpy() if \"std_barC\" in tmp else None\n",
    "\n",
    "            ax.errorbar(x, y, yerr=yerr, marker=\"o\", linewidth=1, capsize=3)\n",
    "            ax.set_title(net)\n",
    "            ax.set_xlabel(\"beta\") # change T / beta\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        axes[0].set_ylabel(\"Mean cooperation (barC)\")\n",
    "        fig.suptitle(f\"barC vs beta — {short_strategy(strat)}\", y=1.05) # change T / beta\n",
    "        fig.tight_layout()\n",
    "        show_saved(fig, f\"barC_vs_beta__{short_strategy(strat)}.png\") # change T / beta\n",
    "\n",
    "def plot_fixation_probs(summary_df, networks=None, strategies=None):\n",
    "    \"\"\"\n",
    "    Pr_allC(T) and Pr_allD(T) for each network, one panel per strategy.\n",
    "    \"\"\"\n",
    "    networks = networks or unique_levels(summary_df, \"network\")\n",
    "    strategies = strategies or unique_levels(summary_df, \"strategy\")\n",
    "\n",
    "    for strat in strategies:\n",
    "        sub = summary_df[summary_df[\"strategy\"] == strat].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        ncols = len(networks)\n",
    "        fig, axes = plt.subplots(1, ncols, figsize=(4*ncols, 3), sharey=True)\n",
    "        if ncols == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for ax, net in zip(axes, networks):\n",
    "            tmp = sub[sub[\"network\"] == net].sort_values(\"T\")\n",
    "            if tmp.empty:\n",
    "                ax.set_title(net + \" (no data)\")\n",
    "                continue\n",
    "\n",
    "            x = tmp[\"T\"].to_numpy()\n",
    "            yC = tmp[\"Pr_allC\"].to_numpy() if \"Pr_allC\" in tmp else None\n",
    "            yD = tmp[\"Pr_allD\"].to_numpy() if \"Pr_allD\" in tmp else None\n",
    "\n",
    "            if yC is not None:\n",
    "                ax.plot(x, yC, marker=\"o\", linewidth=1, label=\"Pr(all-C)\")\n",
    "            if yD is not None:\n",
    "                ax.plot(x, yD, marker=\"o\", linewidth=1, label=\"Pr(all-D)\")\n",
    "\n",
    "            ax.set_title(net)\n",
    "            ax.set_xlabel(\"beta\") # change T / beta\n",
    "            ax.set_ylim(-0.05, 1.05)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(loc=\"best\", fontsize=8)\n",
    "\n",
    "        axes[0].set_ylabel(\"Fixation probability\")\n",
    "        fig.suptitle(f\"Fixation vs beta — {short_strategy(strat)}\", y=1.05) # change T / beta\n",
    "        fig.tight_layout()\n",
    "        show_saved(fig, f\"fixation_vs_beta__{short_strategy(strat)}.png\") # change T / beta\n",
    "\n",
    "def plot_absorption_time(summary_df, networks=None, strategies=None):\n",
    "    \"\"\"\n",
    "    mean_t_absorb(T) with error bars (std_t_absorb) for each network, one panel per strategy.\n",
    "    \"\"\"\n",
    "    networks = networks or unique_levels(summary_df, \"network\")\n",
    "    strategies = strategies or unique_levels(summary_df, \"strategy\")\n",
    "\n",
    "    for strat in strategies:\n",
    "        sub = summary_df[summary_df[\"strategy\"] == strat].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        ncols = len(networks)\n",
    "        fig, axes = plt.subplots(1, ncols, figsize=(4*ncols, 3), sharey=True)\n",
    "        if ncols == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for ax, net in zip(axes, networks):\n",
    "            tmp = sub[sub[\"network\"] == net].sort_values(\"T\")\n",
    "            if tmp.empty:\n",
    "                ax.set_title(net + \" (no data)\")\n",
    "                continue\n",
    "\n",
    "            x = tmp[\"T\"].to_numpy()\n",
    "            y = tmp[\"mean_t_absorb\"].to_numpy() if \"mean_t_absorb\" in tmp else None\n",
    "            yerr = tmp[\"std_t_absorb\"].to_numpy() if \"std_t_absorb\" in tmp else None\n",
    "\n",
    "            ax.errorbar(x, y, yerr=yerr, marker=\"o\", linewidth=1, capsize=3)\n",
    "            ax.set_title(net)\n",
    "            ax.set_xlabel(\"beta\") # change T / beta\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        axes[0].set_ylabel(\"Mean time to absorption\")\n",
    "        fig.suptitle(f\"Absorption time vs beta — {short_strategy(strat)}\", y=1.05) # change T / beta\n",
    "        fig.tight_layout()\n",
    "        show_saved(fig, f\"t_absorb_vs_beta__{short_strategy(strat)}.png\") # change T / beta\n",
    "\n",
    "# =========================\n",
    "# 5) Percolation-style plots (Smax and chi) + Tc markers\n",
    "# =========================\n",
    "def add_Tc_lines(ax, tc_sub):\n",
    "    \"\"\"\n",
    "    Draw vertical lines for any Tc columns present in Tc.csv\n",
    "    \"\"\"\n",
    "    if tc_sub.empty:\n",
    "        return\n",
    "    # common names you might have used\n",
    "    ## for Tc\n",
    "    #candidate_cols = [\n",
    "    #    \"Tc_peak_chi\", \"Tc_inflect_smax\", \"Tc_mid_smax\", \"Tc_threshold_barC\", \"Tc_threshold_smax\"\n",
    "    #]\n",
    "\n",
    "    ## for Beta\n",
    "    candidate_cols = [\n",
    "    \"beta_c_peak_chi\",\n",
    "    \"beta_c_inflect_smax\",\n",
    "    \"beta_c_mid_smax\",\n",
    "    \"beta_c_thr_C\",\n",
    "    \"beta_c_thr_Smax\",\n",
    "]\n",
    "\n",
    "    for c in candidate_cols:\n",
    "        if c in tc_sub.columns:\n",
    "            val = tc_sub[c].iloc[0]\n",
    "            if pd.notna(val):\n",
    "                ax.axvline(val, linestyle=\"--\", linewidth=1, label=c)\n",
    "\n",
    "def plot_Smax_and_chi(summary_df, tc_df, networks=None, strategies=None):\n",
    "    \"\"\"\n",
    "    For each (strategy, network): plot mean_smax(T) and mean_chi(T) if available,\n",
    "    and overlay Tc estimates from Tc.csv.\n",
    "    \"\"\"\n",
    "    networks = networks or unique_levels(summary_df, \"network\")\n",
    "    strategies = strategies or unique_levels(summary_df, \"strategy\")\n",
    "\n",
    "    has_smax = \"mean_smax\" in summary_df.columns\n",
    "    has_chi  = \"mean_chi\" in summary_df.columns\n",
    "\n",
    "    if not (has_smax or has_chi):\n",
    "        print(\"summary_revised.csv has no mean_smax/mean_chi columns; skipping Smax/chi plots.\")\n",
    "        return\n",
    "\n",
    "    for strat in strategies:\n",
    "        for net in networks:\n",
    "            tmp = summary_df[(summary_df[\"strategy\"] == strat) & (summary_df[\"network\"] == net)].sort_values(\"T\")\n",
    "            if tmp.empty:\n",
    "                continue\n",
    "\n",
    "            # find Tc row if it exists\n",
    "            tc_sub = tc_df.copy()\n",
    "            if \"strategy\" in tc_sub.columns:\n",
    "                tc_sub = tc_sub[tc_sub[\"strategy\"] == strat]\n",
    "            if \"network\" in tc_sub.columns:\n",
    "                tc_sub = tc_sub[tc_sub[\"network\"] == net]\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "            x = tmp[\"T\"].to_numpy()\n",
    "\n",
    "            if has_smax and tmp[\"mean_smax\"].notna().any():\n",
    "                ax.plot(x, tmp[\"mean_smax\"].to_numpy(), marker=\"o\", linewidth=1, label=\"mean_smax\")\n",
    "\n",
    "            if has_chi and tmp[\"mean_chi\"].notna().any():\n",
    "                ax.plot(x, tmp[\"mean_chi\"].to_numpy(), marker=\"o\", linewidth=1, label=\"mean_chi\")\n",
    "\n",
    "            add_Tc_lines(ax, tc_sub)\n",
    "\n",
    "            ax.set_title(f\"{net} — {short_strategy(strat)}\")\n",
    "            ax.set_xlabel(\"beta\")  # change T / beta\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(loc=\"best\", fontsize=8)\n",
    "\n",
    "            fig.tight_layout()\n",
    "            show_saved(fig, f\"Smax_chi__{net}__{short_strategy(strat)}.png\")\n",
    "\n",
    "# =========================\n",
    "# 6) Heatmap: mean_barC across (network x T), one heatmap per strategy\n",
    "# =========================\n",
    "def plot_heatmap_barC(summary_df):\n",
    "    \"\"\"\n",
    "    One heatmap per strategy: rows=network, cols=T, values=mean_barC.\n",
    "    \"\"\"\n",
    "    if \"mean_barC\" not in summary_df.columns:\n",
    "        print(\"No mean_barC in summary; skipping heatmap.\")\n",
    "        return\n",
    "\n",
    "    for strat in unique_levels(summary_df, \"strategy\"):\n",
    "        sub = summary_df[summary_df[\"strategy\"] == strat].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        pivot = sub.pivot_table(index=\"network\", columns=\"T\", values=\"mean_barC\", aggfunc=\"mean\")\n",
    "        pivot = pivot.sort_index(axis=0).sort_index(axis=1)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 3))\n",
    "        im = ax.imshow(pivot.to_numpy(dtype=float), aspect=\"auto\")\n",
    "\n",
    "        ax.set_yticks(range(pivot.shape[0]))\n",
    "        ax.set_yticklabels(pivot.index)\n",
    "\n",
    "        ax.set_xticks(range(pivot.shape[1]))\n",
    "        ax.set_xticklabels([f\"{t:.2f}\" for t in pivot.columns], rotation=30, ha=\"right\", size = 6)\n",
    "\n",
    "        ax.set_title(f\"Heatmap of mean_barC — {short_strategy(strat)}\")\n",
    "        ax.set_xlabel(\"beta\")  # change T / beta\n",
    "        ax.set_ylabel(\"Network\")\n",
    "\n",
    "        fig.colorbar(im, ax=ax, label=\"mean_barC\")\n",
    "        fig.tight_layout()\n",
    "        show_saved(fig, f\"heatmap_barC__{short_strategy(strat)}.png\")\n",
    "\n",
    "# =========================\n",
    "# 7) Survival curve (Kaplan–Meier style) for time-to-allD\n",
    "# =========================\n",
    "def km_survival(times, events):\n",
    "    \"\"\"\n",
    "    Simple Kaplan–Meier estimator.\n",
    "    times: array of durations\n",
    "    events: array of 1 (event occurred) or 0 (censored)\n",
    "    returns: t_unique, S(t)\n",
    "    \"\"\"\n",
    "    times = np.asarray(times, dtype=int)\n",
    "    events = np.asarray(events, dtype=int)\n",
    "\n",
    "    order = np.argsort(times)\n",
    "    times = times[order]\n",
    "    events = events[order]\n",
    "\n",
    "    uniq = np.unique(times)\n",
    "    n = len(times)\n",
    "    at_risk = n\n",
    "    S = 1.0\n",
    "    S_list = []\n",
    "    t_list = []\n",
    "\n",
    "    idx = 0\n",
    "    for t in uniq:\n",
    "        # all observations with this time\n",
    "        mask = (times == t)\n",
    "        d_i = events[mask].sum()          # number of events at t\n",
    "        n_i = mask.sum()                  # total at this time (events+censored)\n",
    "\n",
    "        if at_risk > 0:\n",
    "            if d_i > 0:\n",
    "                S *= (1.0 - d_i / at_risk)\n",
    "        t_list.append(t)\n",
    "        S_list.append(S)\n",
    "\n",
    "        at_risk -= n_i\n",
    "\n",
    "    return np.array(t_list), np.array(S_list)\n",
    "\n",
    "def plot_survival_allD(per_run_df, steps_cap=1000):\n",
    "    \"\"\"\n",
    "    Plot KM survival: P(not yet all-D by time t).\n",
    "    One figure per (network, strategy), with multiple T curves.\n",
    "    \"\"\"\n",
    "    if \"absorb_state\" not in per_run_df.columns:\n",
    "        print(\"No absorb_state in per_run; skipping survival plots.\")\n",
    "        return\n",
    "\n",
    "    for strat in unique_levels(per_run_df, \"strategy\"):\n",
    "        for net in unique_levels(per_run_df, \"network\"):\n",
    "            sub = per_run_df[(per_run_df[\"strategy\"] == strat) & (per_run_df[\"network\"] == net)].copy()\n",
    "            if sub.empty:\n",
    "                continue\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "            for T in sorted(sub[\"T\"].dropna().unique()):\n",
    "                tmp = sub[sub[\"T\"] == T]\n",
    "\n",
    "                # event: allD; censor otherwise (allC or None) at observed t_absorb\n",
    "                times = tmp[\"t_absorb\"].to_numpy(dtype=int)\n",
    "                events = (tmp[\"absorb_state\"].astype(str) == \"allD\").astype(int).to_numpy()\n",
    "\n",
    "                # if your pipeline uses steps_cap as \"no absorption\", KM naturally handles censoring\n",
    "                tt, SS = km_survival(times, events)\n",
    "                ax.step(tt, SS, where=\"post\", label=f\"beta={T:.2f}\") # change T/beta\n",
    "\n",
    "\n",
    "            ax.set_title(f\"Survival to all-D — {net} — {short_strategy(strat)}\")\n",
    "            ax.set_xlabel(\"t\")\n",
    "            ax.set_ylabel(\"P(not all-D yet)\")\n",
    "            ax.set_ylim(-0.05, 1.05)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(loc=\"best\", fontsize=7, ncol=2)\n",
    "\n",
    "            fig.tight_layout()\n",
    "            show_saved(fig, f\"survival_allD__{net}__{short_strategy(strat)}.png\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# 8) RUN ALL PLOTS\n",
    "# =========================\n",
    "plot_barC_by_T(summary, networks=networks, strategies=strategies)\n",
    "plot_fixation_probs(summary, networks=networks, strategies=strategies)\n",
    "plot_absorption_time(summary, networks=networks, strategies=strategies)\n",
    "\n",
    "plot_Smax_and_chi(summary, tc, networks=networks, strategies=strategies)\n",
    "plot_heatmap_barC(summary)\n",
    "\n",
    "plot_survival_allD(per_run, steps_cap=int(per_run[\"t_absorb\"].max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab216f8",
   "metadata": {},
   "source": [
    "## V1 - RQ0: Can cooperation persist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _global_coop_fraction_from_model(model) -> float:\n",
    "    \"\"\"\n",
    "    Uses your existing NetworkSimulation._get_state():\n",
    "      state[node] = 1 if action == \"D\" else 0\n",
    "    So mean(state) = fraction of defectors, hence cooperation fraction = 1 - mean(state).\n",
    "    \"\"\"\n",
    "    state = model._get_state()  # dict: node -> 0/1\n",
    "    frac_D = np.mean(list(state.values())) if state else 0.0\n",
    "    return 1.0 - float(frac_D)\n",
    "\n",
    "def _all_same_signature(model):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      \"all-C\" if everyone is cooperating,\n",
    "      \"all-D\" if everyone is defecting,\n",
    "      None otherwise.\n",
    "    \"\"\"\n",
    "    state = model._get_state()\n",
    "    if not state:\n",
    "        return None\n",
    "    vals = list(state.values())\n",
    "    s = sum(vals)\n",
    "    if s == 0:\n",
    "        return \"all-C\"\n",
    "    if s == len(vals):\n",
    "        return \"all-D\"\n",
    "    return None\n",
    "\n",
    "def run_one_condition_and_measure(\n",
    "    *,\n",
    "    model_class,                 # e.g., NetworkSimulation\n",
    "    kind: str,                   # e.g., \"erdos_renyi\", \"watts_strogatz\", \"grid\", \"stochastic_block\", ...\n",
    "    n: int,\n",
    "    graph_kwargs: dict,\n",
    "    payoff_matrix: dict,\n",
    "    strategy_cls,\n",
    "    strategy_kwargs: dict,\n",
    "    seed: int,\n",
    "    T_burn: int,\n",
    "    W: int,\n",
    "    history_window: int = 5,\n",
    "    store_history: bool = True,\n",
    "    absorb_confirm_steps: int = 20,\n",
    "    max_steps: int = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulate and compute:\n",
    "      - time series C(t) for t=1..T_burn+W (or shorter if max_steps is smaller)\n",
    "      - barC over window (T_burn+1 .. T_burn+W)\n",
    "      - absorption info: absorbed?, type, time_to_absorption\n",
    "    No class modifications required.\n",
    "    \"\"\"\n",
    "    total_needed = T_burn + W\n",
    "    if max_steps is not None:\n",
    "        total_needed = min(total_needed, max_steps)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # IMPORTANT: disable snapshots to save memory; we compute C(t) directly\n",
    "    model = model_class(\n",
    "        kind=kind,\n",
    "        n=n,\n",
    "        seed=seed,\n",
    "        rounds=0,  # we'll step manually\n",
    "        strategy=strategy_cls,\n",
    "        strategy_kwargs=strategy_kwargs or {},\n",
    "        payoff_matrix=payoff_matrix,\n",
    "        rng=rng,\n",
    "        history_window=history_window,\n",
    "        store_history=store_history,\n",
    "        store_snapshots=False,\n",
    "        **(graph_kwargs or {}),\n",
    "    )\n",
    "\n",
    "    C_series = []\n",
    "    absorbed = False\n",
    "    absorb_type = None\n",
    "    t_absorb = None\n",
    "\n",
    "    # Empirical absorption confirmation (robust to strategies with randomness/exploration):\n",
    "    candidate = None\n",
    "    candidate_start = None\n",
    "    candidate_count = 0\n",
    "\n",
    "    t = 0\n",
    "    while t < total_needed:\n",
    "        model.step()\n",
    "        t += 1\n",
    "\n",
    "        # record global cooperation C(t)\n",
    "        Ct = _global_coop_fraction_from_model(model)\n",
    "        C_series.append(Ct)\n",
    "\n",
    "        sig = _all_same_signature(model)  # None / \"all-C\" / \"all-D\"\n",
    "\n",
    "        if sig is None:\n",
    "            candidate = None\n",
    "            candidate_start = None\n",
    "            candidate_count = 0\n",
    "        else:\n",
    "            if candidate is None or sig != candidate:\n",
    "                candidate = sig\n",
    "                candidate_start = t\n",
    "                candidate_count = 1\n",
    "            else:\n",
    "                candidate_count += 1\n",
    "\n",
    "            # confirm absorption only after consecutive all-same states\n",
    "            if candidate_count >= absorb_confirm_steps:\n",
    "                absorbed = True\n",
    "                absorb_type = candidate\n",
    "                t_absorb = candidate_start  # first time it became all-same in this run\n",
    "\n",
    "                # We can stop simulating and fill remaining C(t) deterministically\n",
    "                fill_value = 1.0 if absorb_type == \"all-C\" else 0.0\n",
    "                remaining = total_needed - t\n",
    "                if remaining > 0:\n",
    "                    C_series.extend([fill_value] * remaining)\n",
    "                break\n",
    "\n",
    "    # Compute barC over the window (T_burn+1 .. T_burn+W)\n",
    "    if len(C_series) < total_needed:\n",
    "        # should not happen, but safe\n",
    "        C_series += [C_series[-1]] * (total_needed - len(C_series))\n",
    "\n",
    "    window = C_series[T_burn : T_burn + W]  \n",
    "    barC = float(np.mean(window)) if len(window) > 0 else float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"barC\": barC,\n",
    "        \"C_series\": C_series,                 # optional, useful for plotting\n",
    "        \"absorbed\": absorbed,\n",
    "        \"absorb_type\": absorb_type,           # \"all-C\" / \"all-D\" / None\n",
    "        \"time_to_absorption\": t_absorb,       # step index (t) or None\n",
    "        \"T_burn\": T_burn,\n",
    "        \"W\": W,\n",
    "        \"total_steps\": total_needed,\n",
    "    }\n",
    "\n",
    "def evaluate_grid_of_conditions(\n",
    "    *,\n",
    "    model_class,\n",
    "    networks,         \n",
    "    payoff_matrices,   \n",
    "    strategies,       \n",
    "    seeds,             \n",
    "    T_burn: int,\n",
    "    W: int,\n",
    "    history_window: int = 5,\n",
    "    store_history: bool = True,\n",
    "    absorb_confirm_steps: int = 20,\n",
    "    max_steps: int = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs all combinations and returns:\n",
    "      - per-run results\n",
    "      - aggregated fixation probabilities Pr(all-C), Pr(all-D)\n",
    "      - average barC across seeds\n",
    "      - mean time to absorption (for absorbed runs)\n",
    "    \"\"\"\n",
    "    per_run = []\n",
    "    # group key for aggregation\n",
    "    grouped = defaultdict(list)\n",
    "\n",
    "    for net, (pm_name, pm), strat, seed in product(\n",
    "        networks, payoff_matrices.items(), strategies, seeds\n",
    "    ):\n",
    "        res = run_one_condition_and_measure(\n",
    "            model_class=model_class,\n",
    "            kind=net[\"kind\"],\n",
    "            n=net[\"n\"],\n",
    "            graph_kwargs=net.get(\"graph_kwargs\", {}),\n",
    "            payoff_matrix=pm,\n",
    "            strategy_cls=strat[\"cls\"],\n",
    "            strategy_kwargs=strat.get(\"kwargs\", {}),\n",
    "            seed=seed,\n",
    "            T_burn=T_burn,\n",
    "            W=W,\n",
    "            history_window=history_window,\n",
    "            store_history=store_history,\n",
    "            absorb_confirm_steps=absorb_confirm_steps,\n",
    "            max_steps=max_steps,\n",
    "        )\n",
    "\n",
    "        row = {\n",
    "            \"network\": net.get(\"name\", net[\"kind\"]),\n",
    "            \"kind\": net[\"kind\"],\n",
    "            \"n\": net[\"n\"],\n",
    "            \"payoff\": pm_name,\n",
    "            \"strategy\": strat[\"name\"],\n",
    "            \"seed\": seed,\n",
    "            **res,\n",
    "        }\n",
    "        per_run.append(row)\n",
    "\n",
    "        key = (row[\"network\"], row[\"payoff\"], row[\"strategy\"])\n",
    "        grouped[key].append(row)\n",
    "\n",
    "    # Aggregation\n",
    "    summary = []\n",
    "    for (net_name, pm_name, strat_name), rows in grouped.items():\n",
    "        barCs = [r[\"barC\"] for r in rows]\n",
    "        pr_allC = np.mean([r[\"absorb_type\"] == \"all-C\" for r in rows])\n",
    "        pr_allD = np.mean([r[\"absorb_type\"] == \"all-D\" for r in rows])\n",
    "\n",
    "        t_abs = [r[\"time_to_absorption\"] for r in rows if r[\"time_to_absorption\"] is not None]\n",
    "        mean_t_abs = float(np.mean(t_abs)) if len(t_abs) else None\n",
    "\n",
    "        summary.append({\n",
    "            \"network\": net_name,\n",
    "            \"payoff\": pm_name,\n",
    "            \"strategy\": strat_name,\n",
    "            \"mean_barC\": float(np.mean(barCs)),\n",
    "            \"std_barC\": float(np.std(barCs, ddof=1)) if len(barCs) > 1 else 0.0,\n",
    "            \"Pr_allC\": float(pr_allC),\n",
    "            \"Pr_allD\": float(pr_allD),\n",
    "            \"mean_time_to_absorption\": mean_t_abs,\n",
    "            \"n_runs\": len(rows),\n",
    "        })\n",
    "\n",
    "    return summary, per_run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28404e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = [\n",
    "    # --- Spatial / highly clustered baseline ---\n",
    "    {\"name\": \"Grid_20x20\", \"kind\": \"grid\", \"n\": 400, \"graph_kwargs\": {\"periodic\": False}},\n",
    "\n",
    "    # --- Random baseline (match mean degree) ---\n",
    "    # For ER: mean degree ≈ p*(n-1). With n=400, p=0.02 => ~7.98\n",
    "    {\"name\": \"ER_p0.02\", \"kind\": \"erdos_renyi\", \"n\": 400, \"graph_kwargs\": {\"p\": 0.02}},\n",
    "    # A sparser ER for sensitivity\n",
    "    {\"name\": \"ER_p0.015\", \"kind\": \"erdos_renyi\", \"n\": 400, \"graph_kwargs\": {\"p\": 0.015}},  # ~6\n",
    "\n",
    "    # --- Small-world: same ring degree k, tune rewiring p ---\n",
    "    # WS requires k even; mean degree = k\n",
    "    {\"name\": \"WS_k8_p0.01\", \"kind\": \"watts_strogatz\", \"n\": 400, \"graph_kwargs\": {\"k\": 8, \"p\": 0.01}},\n",
    "    {\"name\": \"WS_k8_p0.1\",  \"kind\": \"watts_strogatz\", \"n\": 400, \"graph_kwargs\": {\"k\": 8, \"p\": 0.1}},\n",
    "    {\"name\": \"WS_k8_p0.5\",  \"kind\": \"watts_strogatz\", \"n\": 400, \"graph_kwargs\": {\"k\": 8, \"p\": 0.5}},\n",
    "\n",
    "    # --- Preferential attachment (degree-heterogeneous) ---\n",
    "    # BA mean degree ≈ 2m. Choose m=4 => mean degree ≈ 8 (matches ER p=0.02 and WS k=8)\n",
    "    {\"name\": \"BA_m4\", \"kind\": \"barabasi_albert\", \"n\": 400, \"graph_kwargs\": {\"m\": 4}},\n",
    "\n",
    "    # --- Stochastic Block Model (community structure) ---\n",
    "    # Two equal communities; within >> between. Tune p_in/p_out while keeping mean degree reasonable.\n",
    "    # Expected mean degree ≈ (n1-1)*p_in + n2*p_out for a node in block 1 (similarly for block 2).\n",
    "    # For n1=n2=200, p_in=0.05, p_out=0.005 => ~199*0.05 + 200*0.005 ≈ 9.95 + 1 = 10.95\n",
    "    {\"name\": \"SBM_2block_strong\",\n",
    "     \"kind\": \"stochastic_block\",\n",
    "     \"n\": 400,\n",
    "     \"graph_kwargs\": {\n",
    "         \"sizes\": [200, 200],\n",
    "         \"p\": [[0.05, 0.005],\n",
    "               [0.005, 0.05]]\n",
    "     }},\n",
    "    # Milder communities (closer to ER-like)\n",
    "    {\"name\": \"SBM_2block_mild\",\n",
    "     \"kind\": \"stochastic_block\",\n",
    "     \"n\": 400,\n",
    "     \"graph_kwargs\": {\n",
    "         \"sizes\": [200, 200],\n",
    "         \"p\": [[0.03, 0.015],\n",
    "               [0.015, 0.03]]\n",
    "     }},\n",
    "]\n",
    "\n",
    "\n",
    "strategies = [\n",
    "    {\"name\": \"ActionStrategy\", \"cls\": ActionStrategy, \"kwargs\": {}},\n",
    "    {\"name\": \"ImitationStrategy\", \"cls\": ImitationStrategy, \"kwargs\": {}},\n",
    "    {\"name\": \"Fermi(K=0.5)\", \"cls\": FermiStrategy, \"kwargs\": {\"temperature\": 0.5}},\n",
    "    {\"name\": \"RLStrategy(learning_rate=0.1, epsilon=0.1, initial_q=0.0)\", \"cls\": ReinforcementLearningStrategy, \"kwargs\": {\"learning_rate\": 0.1, \"epsilon\": 0.1, \"initial_q\": 0.0}}\n",
    "]\n",
    "\n",
    "payoffs = {\n",
    "    \"Default\": payoff_matrices[\"Default\"],\n",
    "    \"Canonical\": payoff_matrices[\"Canonical\"],\n",
    "    \"Friend or Foe\": payoff_matrices[\"Friend or Foe\"],\n",
    "    \"Snowdrift\": payoff_matrices[\"Snowdrift\"],\n",
    "    \"Prisoners\": payoff_matrices[\"Prisoners\"]\n",
    "}\n",
    "\n",
    "summary, per_run = evaluate_grid_of_conditions(\n",
    "    model_class=NetworkSimulation,\n",
    "    networks=networks,\n",
    "    payoff_matrices=payoffs,\n",
    "    strategies=strategies,\n",
    "    seeds=range(10),     # 10 replicates\n",
    "    T_burn=200,\n",
    "    W=300,\n",
    "    absorb_confirm_steps=20,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3c2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(summary).sort_values(\n",
    "    [\"payoff\", \"strategy\", \"network\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66493b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_run_df = pd.DataFrame(per_run).sort_values(\n",
    "    [\"payoff\", \"strategy\", \"network\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "per_run_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b51d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"Result_RQ0\", exist_ok=True)\n",
    "summary_df.to_csv(\"Result_RQ0/summary_df.csv\", index=False)\n",
    "per_run_df.to_csv(\"Result_RQ0/per_run_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d78d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoff_name = \"Canonical\"  # change\n",
    "pivot_Can = (summary_df[summary_df[\"payoff\"] == payoff_name]\n",
    "         .pivot_table(index=\"network\", columns=\"strategy\", values=\"mean_barC\"))\n",
    "pivot_Can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca58dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoff_name = \"Snowdrift\"  # change\n",
    "pivot_Snow = (summary_df[summary_df[\"payoff\"] == payoff_name]\n",
    "         .pivot_table(index=\"network\", columns=\"strategy\", values=\"mean_barC\"))\n",
    "pivot_Snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoff_name = \"Default\"  # change\n",
    "pivot_Default = (summary_df[summary_df[\"payoff\"] == payoff_name]\n",
    "         .pivot_table(index=\"network\", columns=\"strategy\", values=\"mean_barC\"))\n",
    "pivot_Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoff_name = \"Friend or Foe\"  # change\n",
    "pivot_Foe = (summary_df[summary_df[\"payoff\"] == payoff_name]\n",
    "         .pivot_table(index=\"network\", columns=\"strategy\", values=\"mean_barC\"))\n",
    "pivot_Foe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9276544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payoff_name = \"Prisoners\"  # change\n",
    "pivot_Prison = (summary_df[summary_df[\"payoff\"] == payoff_name]\n",
    "         .pivot_table(index=\"network\", columns=\"strategy\", values=\"mean_barC\"))\n",
    "pivot_Prison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23102041",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_Can.to_csv(\"Result_RQ0/pivot_Can.csv\", index=False)\n",
    "pivot_Default.to_csv(\"Result_RQ0/pivot_Default.csv\", index=False)\n",
    "pivot_Foe.to_csv(\"Result_RQ0/pivot_Foe.csv\", index=False)\n",
    "pivot_Prison.to_csv(\"Result_RQ0/pivot_Prison.csv\", index=False)\n",
    "pivot_Snow.to_csv(\"Result_RQ0/pivot_Snow.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b374fd9",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4415358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_strategy_short(df, col=\"strategy\"):\n",
    "    def short(s):\n",
    "        if \"ActionStrategy\" in s: return \"Action\"\n",
    "        if \"ImitationStrategy\" in s: return \"Imitate\"\n",
    "        if \"Fermi\" in s: return \"Fermi\"\n",
    "        if \"RLStrategy\" in s or \"Reinforcement\" in s: return \"RL\"\n",
    "        return re.sub(r\"\\(.*\\)\", \"\", s)  # fallback\n",
    "    df = df.copy()\n",
    "    df[\"strategy_short\"] = df[col].astype(str).map(short)\n",
    "    return df\n",
    "\n",
    "summary_df = add_strategy_short(summary_df, col=\"strategy\")\n",
    "per_run_df = add_strategy_short(per_run_df, col=\"strategy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1feb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"figures\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "def show_saved(fig, filename, dpi=200):\n",
    "    path = os.path.join(OUTDIR, filename)\n",
    "    fig.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    display(Image(filename=path))\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_mean_barC_save(df, payoff_name, col=\"strategy\"):\n",
    "    sub = df[df[\"payoff\"] == payoff_name].copy()\n",
    "    if \"strategy_short\" in sub.columns:\n",
    "        col = \"strategy_short\"\n",
    "    mat = sub.pivot_table(index=\"network\", columns=col, values=\"mean_barC\", aggfunc=\"mean\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 4))\n",
    "    im = ax.imshow(mat.to_numpy(dtype=float), aspect=\"auto\")\n",
    "    fig.colorbar(im, ax=ax, label=\"mean_barC\")\n",
    "\n",
    "    ax.set_xticks(range(mat.shape[1]))\n",
    "    ax.set_xticklabels(mat.columns, rotation=30, ha=\"right\")\n",
    "    ax.set_yticks(range(mat.shape[0]))\n",
    "    ax.set_yticklabels(mat.index)\n",
    "    ax.set_title(f\"Mean cooperation (barC) — {payoff_name}\")\n",
    "\n",
    "    # annotate numbers\n",
    "    for i in range(mat.shape[0]):\n",
    "        for j in range(mat.shape[1]):\n",
    "            v = mat.iat[i, j]\n",
    "            if np.isfinite(v):\n",
    "                ax.text(j, i, f\"{v:.2f}\", ha=\"center\", va=\"center\", fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return show_saved(fig, f\"heatmap_{payoff_name}.png\")\n",
    "\n",
    "heatmap_mean_barC_save(summary_df, \"Prisoners\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_groupedbars_mean_barC(summary_df, payoff_name, use_short=True):\n",
    "    sub = summary_df[summary_df[\"payoff\"] == payoff_name].copy()\n",
    "    strat_col = \"strategy_short\" if (use_short and \"strategy_short\" in sub.columns) else \"strategy\"\n",
    "\n",
    "    pivot = sub.pivot_table(index=\"network\", columns=strat_col, values=\"mean_barC\", aggfunc=\"mean\")\n",
    "    networks = list(pivot.index)\n",
    "    strategies = list(pivot.columns)\n",
    "\n",
    "    x = np.arange(len(networks))\n",
    "    width = 0.8 / max(len(strategies), 1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    for k, s in enumerate(strategies):\n",
    "        ax.bar(x + (k - (len(strategies)-1)/2)*width, pivot[s].values, width, label=str(s))\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(networks, rotation=30, ha=\"right\")\n",
    "    ax.set_ylabel(\"mean_barC\")\n",
    "    ax.set_title(f\"Mean cooperation by network × strategy — {payoff_name}\")\n",
    "    ax.legend(ncols=min(4, len(strategies)), fontsize=8)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return show_saved(fig, f\"groupedbars_mean_barC_{payoff_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991670d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_groupedbars_mean_barC(summary_df, \"Snowdrift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bfe0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_persistence_rate(per_run_df, payoff_name, threshold=0.2, y_candidates=(\"barC_final\",\"barC\",\"mean_barC\")):\n",
    "    sub = per_run_df[per_run_df[\"payoff\"] == payoff_name].copy()\n",
    "\n",
    "    ycol = None\n",
    "    for c in y_candidates:\n",
    "        if c in sub.columns:\n",
    "            ycol = c\n",
    "            break\n",
    "    if ycol is None:\n",
    "        raise ValueError(f\"Can't find any of {y_candidates} in per_run_df columns: {list(sub.columns)}\")\n",
    "\n",
    "    # rate by network × strategy\n",
    "    rate = (sub.assign(persist=sub[ycol] >= threshold)\n",
    "              .groupby([\"network\",\"strategy\"])[\"persist\"]\n",
    "              .mean()\n",
    "              .reset_index())\n",
    "\n",
    "    pivot = rate.pivot_table(index=\"network\", columns=\"strategy\", values=\"persist\", aggfunc=\"mean\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    im = ax.imshow(pivot.to_numpy(dtype=float), aspect=\"auto\", vmin=0, vmax=1)\n",
    "    fig.colorbar(im, ax=ax, label=f\"P(persist: {ycol} ≥ {threshold})\")\n",
    "\n",
    "    ax.set_xticks(range(pivot.shape[1]))\n",
    "    ax.set_xticklabels(pivot.columns, rotation=30, ha=\"right\")\n",
    "    ax.set_yticks(range(pivot.shape[0]))\n",
    "    ax.set_yticklabels(pivot.index)\n",
    "    ax.set_title(f\"Cooperation persistence rate — {payoff_name}\")\n",
    "\n",
    "    # annotate\n",
    "    for i in range(pivot.shape[0]):\n",
    "        for j in range(pivot.shape[1]):\n",
    "            v = pivot.iat[i, j]\n",
    "            if np.isfinite(v):\n",
    "                ax.text(j, i, f\"{v:.2f}\", ha=\"center\", va=\"center\", fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return show_saved(fig, f\"persistence_rate_{payoff_name}_thr{threshold}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29604b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_persistence_rate(\n",
    "    per_run_df,\n",
    "    payoff_name,\n",
    "    threshold=0.2,\n",
    "    y_candidates=(\"barC_final\", \"barC\", \"mean_barC\"),\n",
    "    strat_col=\"strategy_short\",                 # <-- use shortened names\n",
    "    strat_order=(\"Action\", \"Imitate\", \"Fermi\", \"RL\"),\n",
    "):\n",
    "    sub = per_run_df[per_run_df[\"payoff\"] == payoff_name].copy()\n",
    "\n",
    "    # pick the first available y column\n",
    "    ycol = next((c for c in y_candidates if c in sub.columns), None)\n",
    "    if ycol is None:\n",
    "        raise ValueError(\n",
    "            f\"Can't find any of {y_candidates} in per_run_df columns: {list(sub.columns)}\"\n",
    "        )\n",
    "\n",
    "    # if strategy_short is missing, fall back to strategy (but better to create it earlier)\n",
    "    if strat_col not in sub.columns:\n",
    "        strat_col = \"strategy\"\n",
    "        print(\"Warning: 'strategy_short' not found. Falling back to 'strategy'.\")\n",
    "\n",
    "    # rate by network × (short) strategy\n",
    "    rate = (\n",
    "        sub.assign(persist=sub[ycol] >= threshold)\n",
    "           .groupby([\"network\", strat_col], as_index=False)[\"persist\"]\n",
    "           .mean()\n",
    "    )\n",
    "\n",
    "    pivot = rate.pivot_table(\n",
    "        index=\"network\",\n",
    "        columns=strat_col,\n",
    "        values=\"persist\",\n",
    "        aggfunc=\"mean\"\n",
    "    )\n",
    "\n",
    "    # enforce a clean strategy order if those columns exist\n",
    "    if strat_order is not None:\n",
    "        cols = [c for c in strat_order if c in pivot.columns]\n",
    "        rest = [c for c in pivot.columns if c not in cols]\n",
    "        pivot = pivot[cols + rest]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    im = ax.imshow(pivot.to_numpy(dtype=float), aspect=\"auto\", vmin=0, vmax=1)\n",
    "    fig.colorbar(im, ax=ax, label=f\"P(persist: {ycol} ≥ {threshold})\")\n",
    "\n",
    "    ax.set_xticks(range(pivot.shape[1]))\n",
    "    ax.set_xticklabels(pivot.columns, rotation=0)  # short labels, no rotation needed\n",
    "    ax.set_yticks(range(pivot.shape[0]))\n",
    "    ax.set_yticklabels(pivot.index)\n",
    "    ax.set_title(f\"Cooperation persistence rate — {payoff_name}\")\n",
    "\n",
    "    # annotate numbers\n",
    "    for i in range(pivot.shape[0]):\n",
    "        for j in range(pivot.shape[1]):\n",
    "            v = pivot.iat[i, j]\n",
    "            if np.isfinite(v):\n",
    "                ax.text(j, i, f\"{v:.2f}\", ha=\"center\", va=\"center\", fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return show_saved(fig, f\"persistence_rate_{payoff_name}_thr{threshold}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524aa17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_persistence_rate(per_run_df, \"Default\", threshold=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
