{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6497bd",
   "metadata": {},
   "source": [
    "# Iterated Prisoner's Dilemma On A Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f664e0b",
   "metadata": {},
   "source": [
    "## Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "857538bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from IPython.display import display, HTML, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import os, json, hashlib\n",
    "import re\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from matplotlib.animation import PillowWriter\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c580c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams[\"animation.embed_limit\"] = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f90464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s - %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7e923",
   "metadata": {},
   "source": [
    "## Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ac0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weak_pd_payoff(T, R =1.0, S = 0.0, P=0.0):\n",
    "    return {\n",
    "        (\"C\",\"C\"):(R,R),\n",
    "        (\"C\",\"D\"):(S,T),\n",
    "        (\"D\",\"C\"):(T,S),\n",
    "        (\"D\",\"D\"):(P,P),\n",
    "    }\n",
    "\n",
    "def make_payoff_grid(T_values):\n",
    "    payoff_mats = {}\n",
    "    for T in T_values:\n",
    "        payoff_mats[f\"T={T:.2f}\"] = make_weak_pd_payoff(T=T)\n",
    "    return payoff_mats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9125a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "payoff_matrices = {\n",
    "    \"Default\": {\n",
    "        (\"C\", \"C\"): (3, 3),\n",
    "        (\"C\", \"D\"): (0, 4),\n",
    "        (\"D\", \"C\"): (4, 0),\n",
    "        (\"D\", \"D\"): (1, 1),\n",
    "    },\n",
    "    #\"Canonical\": {\n",
    "    #   (\"C\", \"C\"): (-1, -1),\n",
    "    #   (\"C\", \"D\"): (-3, 0),\n",
    "    #   (\"D\", \"C\"): (0, -3),\n",
    "    #   (\"D\", \"D\"): (-2, -2),\n",
    "    #},\n",
    "    \"Snowdrift\": {\n",
    "        (\"C\", \"C\"): (500, 500),\n",
    "        (\"C\", \"D\"): (200, 800),\n",
    "        (\"D\", \"C\"): (800, 200),\n",
    "        (\"D\", \"D\"): (0, 0),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684ac16",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532e2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Prison import ActionStrategy, ImitationStrategy, FermiStrategy, ReinforcementLearningStrategy, TitForTatStrategy\n",
    "from Prison import Agent, Network, NetworkSimulation\n",
    "from Prison import experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d2424",
   "metadata": {},
   "source": [
    "### Measurement Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f60ab107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coop_fraction(actions_dict):\n",
    "    # actions_dict: node -> 'C'/'D'\n",
    "    n = len(actions_dict)\n",
    "    return sum(1 for a in actions_dict.values() if a == \"C\") / n\n",
    "\n",
    "def coop_component_sizes(G, actions_dict):\n",
    "    coop_nodes = [i for i,a in actions_dict.items() if a == \"C\"]\n",
    "    if len(coop_nodes) == 0:\n",
    "        return []\n",
    "    H = G.subgraph(coop_nodes)\n",
    "    return [len(cc) for cc in nx.connected_components(H)]\n",
    "\n",
    "def smax_fraction(G, actions_dict):\n",
    "    sizes = coop_component_sizes(G, actions_dict)\n",
    "    if not sizes:\n",
    "        return 0.0\n",
    "    return max(sizes) / G.number_of_nodes()\n",
    "\n",
    "def add_strategy_short(df, col=\"strategy\"):\n",
    "    def short(s):\n",
    "        s = str(s)\n",
    "        if \"ActionStrategy\" in s: return \"Action\"\n",
    "        if \"ImitationStrategy\" in s: return \"Imitate\"\n",
    "        if \"Fermi\" in s: return \"Fermi\"\n",
    "        if \"RLStrategy\" in s or \"Reinforcement\" in s: return \"RL\"\n",
    "        if \"TitForTatStrategy\" in s: return \"TFT\"\n",
    "        return re.sub(r\"\\(.*\\)\", \"\", s)\n",
    "    df = df.copy()\n",
    "    df[\"strategy_short\"] = df[col].astype(str).map(short)\n",
    "    return df\n",
    "\n",
    "def susceptibility_from_sizes(sizes):\n",
    "    \"\"\"\n",
    "    sizes: list of component sizes of cooperative subgraph at time t.\n",
    "    returns chi(t) per your definition; 0.0 if undefined.\n",
    "    \"\"\"\n",
    "    if not sizes:\n",
    "        return 0.0\n",
    "    smax = max(sizes)\n",
    "    counts = Counter(sizes)  # n_s\n",
    "\n",
    "    num = 0.0\n",
    "    den = 0.0\n",
    "    for s, ns in counts.items():\n",
    "        if s == smax:\n",
    "            continue\n",
    "        num += (s**2) * ns\n",
    "        den += s * ns\n",
    "    return (num / den) if den > 0 else 0.0\n",
    "\n",
    "def cluster_size_counts_from_sizes(sizes):\n",
    "    \"\"\"sizes: list[int] -> Counter(size -> count).\"\"\"\n",
    "    return Counter(sizes)\n",
    "\n",
    "def singleton_cooperator_fraction(G, actions_dict):\n",
    "    \"\"\"\n",
    "    fraction of cooperators that are isolated singletons (cluster size = 1).\n",
    "    \"\"\"\n",
    "    sizes = coop_component_sizes(G, actions_dict)\n",
    "    if not sizes:\n",
    "        return 0.0\n",
    "    totalC = sum(sizes)\n",
    "    if totalC == 0:\n",
    "        return 0.0\n",
    "    n_single_clusters = sum(1 for s in sizes if s == 1)\n",
    "    single_C = n_single_clusters * 1\n",
    "    return single_C / totalC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f96cc5",
   "metadata": {},
   "source": [
    "## RQ0: Can cooperation persist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9540a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_int(s: str, mod: int = 10_000_000) -> int:\n",
    "    \"\"\"Stable across sessions (unlike Python's built-in hash).\"\"\"\n",
    "    import hashlib\n",
    "    return int(hashlib.md5(str(s).encode(\"utf-8\")).hexdigest()[:8], 16) % mod\n",
    "\n",
    "\n",
    "def normalize_network_spec(net):\n",
    "    \"\"\"\n",
    "    Accept either:\n",
    "      A) dict: {\"name\":..., \"kind\":..., \"n\":..., \"graph_kwargs\": {...}}\n",
    "      B) tuple: (name, dict(kind=..., n=..., ...))\n",
    "    Return dict in form A.\n",
    "    \"\"\"\n",
    "    if isinstance(net, dict):\n",
    "        if \"name\" not in net:\n",
    "            raise ValueError(\"Network dict must include key 'name'.\")\n",
    "        return net\n",
    "\n",
    "    if isinstance(net, tuple) and len(net) == 2 and isinstance(net[1], dict):\n",
    "        name, spec = net\n",
    "        spec = spec.copy()\n",
    "        if \"kind\" not in spec or \"n\" not in spec:\n",
    "            raise ValueError(f\"Network tuple spec must include 'kind' and 'n': {net}\")\n",
    "\n",
    "        kind = spec.pop(\"kind\")\n",
    "        n = spec.pop(\"n\")\n",
    "\n",
    "        graph_kwargs = spec.pop(\"graph_kwargs\", None)\n",
    "        if graph_kwargs is None:\n",
    "            graph_kwargs = spec\n",
    "        else:\n",
    "            merged = dict(spec)\n",
    "            merged.update(graph_kwargs)\n",
    "            graph_kwargs = merged\n",
    "\n",
    "        return {\"name\": name, \"kind\": kind, \"n\": n, \"graph_kwargs\": graph_kwargs}\n",
    "\n",
    "    raise TypeError(f\"Unknown network spec format: {type(net)} -> {net}\")\n",
    "\n",
    "\n",
    "def normalize_strategy_spec(strat):\n",
    "    \"\"\"\n",
    "    Accept either:\n",
    "      A) dict: {\"name\":..., \"cls\": StrategyClass, \"kwargs\": {...}}\n",
    "      B) tuple: (name, StrategyClass) or (name, StrategyClass, kwargs_dict)\n",
    "    Return dict in form A.\n",
    "    \"\"\"\n",
    "    if isinstance(strat, dict):\n",
    "        if \"name\" not in strat or \"cls\" not in strat:\n",
    "            raise ValueError(\"Strategy dict must include keys 'name' and 'cls'.\")\n",
    "        out = strat.copy()\n",
    "        out[\"kwargs\"] = out.get(\"kwargs\", {}) or {}\n",
    "        return out\n",
    "\n",
    "    if isinstance(strat, tuple) and len(strat) in (2, 3):\n",
    "        name = strat[0]\n",
    "        cls = strat[1]\n",
    "        kwargs = strat[2] if len(strat) == 3 else {}\n",
    "        return {\"name\": name, \"cls\": cls, \"kwargs\": kwargs or {}}\n",
    "\n",
    "    raise TypeError(f\"Unknown strategy spec format: {type(strat)} -> {strat}\")\n",
    "\n",
    "\n",
    "def susceptibility_from_sizes(sizes):\n",
    "    \"\"\"\n",
    "    Percolation-style susceptibility:\n",
    "      chi = sum_{s != smax} s^2 n_s / sum_{s != smax} s n_s\n",
    "    where n_s = number of clusters of size s.\n",
    "    \"\"\"\n",
    "    if not sizes:\n",
    "        return 0.0\n",
    "    smax = max(sizes)\n",
    "    counts = Counter(sizes)\n",
    "\n",
    "    num = 0.0\n",
    "    den = 0.0\n",
    "    for s, ns in counts.items():\n",
    "        if s == smax:\n",
    "            continue\n",
    "        num += (s**2) * ns\n",
    "        den += s * ns\n",
    "    return num / den if den > 0 else 0.0\n",
    "\n",
    "\n",
    "def run_one_setting(\n",
    "    net_spec,\n",
    "    strat_spec,\n",
    "    payoff_matrix,\n",
    "    steps=2000,\n",
    "    burn_in=1000,\n",
    "    window=1000,\n",
    "    seed=0,\n",
    "    sample_cluster_every=50,\n",
    "    sanity_check=False,\n",
    "    record_window_sizes=True,\n",
    "    record_samples=True,\n",
    "    max_samples=200,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns per-run summary + recorded cluster sizes.\n",
    "\n",
    "    record_window_sizes:\n",
    "      - if True, store ALL cluster sizes sampled within the averaging window\n",
    "        (best for histogram/CCDF evidence).\n",
    "\n",
    "    record_samples:\n",
    "      - if True, store time-stamped samples (t, sizes), capped by max_samples\n",
    "        (best for \"see evolution\" / debugging).\n",
    "    \"\"\"\n",
    "    net_spec = normalize_network_spec(net_spec)\n",
    "    strat_spec = normalize_strategy_spec(strat_spec)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    sim = NetworkSimulation(\n",
    "        kind=net_spec[\"kind\"],\n",
    "        n=net_spec[\"n\"],\n",
    "        seed=seed,\n",
    "        rounds=0,\n",
    "        strategy=strat_spec[\"cls\"],\n",
    "        strategy_kwargs=strat_spec.get(\"kwargs\", {}) or {},\n",
    "        payoff_matrix=payoff_matrix,\n",
    "        rng=rng,\n",
    "        store_snapshots=False,\n",
    "        **(net_spec.get(\"graph_kwargs\", {}) or {}),\n",
    "    )\n",
    "\n",
    "    G = sim.graph\n",
    "    N = G.number_of_nodes()\n",
    "\n",
    "    C_series = []\n",
    "    Smax_series = []\n",
    "    Chi_series = []\n",
    "\n",
    "    window_sizes_all = []  \n",
    "\n",
    "    cluster_samples = []\n",
    "    samples_kept = 0\n",
    "\n",
    "    absorbed = False\n",
    "    absorb_state = None\n",
    "    t_absorb = None\n",
    "\n",
    "    for t in range(steps):\n",
    "        sim.step()\n",
    "        actions = {node: agent.strategy.action for node, agent in sim.agents.items()}\n",
    "        Ct = coop_fraction(actions)\n",
    "        C_series.append(Ct)\n",
    "\n",
    "        # absorption\n",
    "        if Ct == 1.0:\n",
    "            absorbed, absorb_state, t_absorb = True, \"allC\", t + 1\n",
    "            break\n",
    "        if Ct == 0.0:\n",
    "            absorbed, absorb_state, t_absorb = True, \"allD\", t + 1\n",
    "            break\n",
    "\n",
    "        # sample clusters \n",
    "        do_sample = (sample_cluster_every is not None) and (sample_cluster_every > 0) and ((t % sample_cluster_every) == 0)\n",
    "        if do_sample:\n",
    "            sizes = coop_component_sizes(G, actions)\n",
    "\n",
    "            \n",
    "            if record_samples and (samples_kept < max_samples):\n",
    "                cluster_samples.append({\"t\": t + 1, \"sizes\": sizes})\n",
    "                samples_kept += 1\n",
    "\n",
    "            if burn_in <= t < (burn_in + window):\n",
    "                if record_window_sizes:\n",
    "                    window_sizes_all.extend(sizes)  # flatten\n",
    "                Chi_series.append(susceptibility_from_sizes(sizes))\n",
    "\n",
    "        # Smax in window\n",
    "        if burn_in <= t < (burn_in + window):\n",
    "            Smax_series.append(smax_fraction(G, actions))\n",
    "\n",
    "    C_series = np.asarray(C_series, dtype=float)\n",
    "\n",
    "    # barC over window (clip if ended early)\n",
    "    start = burn_in\n",
    "    end = min(len(C_series), burn_in + window)\n",
    "    barC = float(np.mean(C_series[start:end])) if end > start else float(np.mean(C_series))\n",
    "\n",
    "    smax_bar = float(np.mean(Smax_series)) if len(Smax_series) > 0 else np.nan\n",
    "    chi_bar  = float(np.mean(Chi_series)) if len(Chi_series) > 0 else np.nan\n",
    "\n",
    "    if not absorbed:\n",
    "        t_absorb = steps\n",
    "        absorb_state = None\n",
    "\n",
    "    return {\n",
    "        \"barC\": barC,\n",
    "        \"smax_bar\": smax_bar,\n",
    "        \"chi_bar\": chi_bar,\n",
    "        \"absorbed\": absorbed,\n",
    "        \"absorb_state\": absorb_state,\n",
    "        \"t_absorb\": int(t_absorb),\n",
    "        \"n_steps_executed\": int(len(C_series)),\n",
    "        \"cluster_samples\": cluster_samples,  \n",
    "        \"window_sizes_all\": window_sizes_all,  \n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_revised_plan(\n",
    "    networks,\n",
    "    strategies,\n",
    "    payoff_mats,\n",
    "    runs=30,\n",
    "    steps=2000,\n",
    "    burn_in=1000,\n",
    "    window=1000,\n",
    "    seed0=2026,\n",
    "    outdir=\"Results/Result_RQ0/Result_V5\",\n",
    "    save=True,\n",
    "    sample_cluster_every=50,\n",
    "    record_window_sizes=True,\n",
    "    record_samples=True,\n",
    "    max_samples=200,\n",
    "):\n",
    "    \"\"\"\n",
    "    networks: list of dicts OR list of (name, dict(...))\n",
    "    strategies: list of dicts OR list of (name, cls) / (name, cls, kwargs)\n",
    "    payoff_mats: dict payoff_name -> payoff_matrix\n",
    "\n",
    "    Stores per-run:\n",
    "      - cluster_samples_json: time-stamped samples (capped)\n",
    "      - cluster_sizes_window_json: flattened sizes within averaging window (for distribution evidence)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for payoff_name, payoff_mat in payoff_mats.items():\n",
    "        for net_raw in networks:\n",
    "            net = normalize_network_spec(net_raw)\n",
    "\n",
    "            for strat_raw in strategies:\n",
    "                strat = normalize_strategy_spec(strat_raw)\n",
    "\n",
    "                for r in range(runs):\n",
    "                    seed_run = (\n",
    "                        seed0\n",
    "                        + 100000 * r\n",
    "                        + 1000 * stable_int(payoff_name)\n",
    "                        + 10 * stable_int(net[\"name\"])\n",
    "                        + stable_int(strat[\"name\"])\n",
    "                    )\n",
    "\n",
    "                    res = run_one_setting(\n",
    "                        net_spec=net,\n",
    "                        strat_spec=strat,\n",
    "                        payoff_matrix=payoff_mat,\n",
    "                        steps=steps,\n",
    "                        burn_in=burn_in,\n",
    "                        window=window,\n",
    "                        seed=seed_run,\n",
    "                        sample_cluster_every=sample_cluster_every,\n",
    "                        sanity_check=False,\n",
    "                        record_window_sizes=record_window_sizes,\n",
    "                        record_samples=record_samples,\n",
    "                        max_samples=max_samples,\n",
    "                    )\n",
    "\n",
    "                    rows.append({\n",
    "                        \"payoff\": payoff_name,\n",
    "                        \"network\": net[\"name\"],\n",
    "                        \"strategy\": strat[\"name\"],\n",
    "\n",
    "                        \"barC\": res[\"barC\"],\n",
    "                        \"chi_bar\": res[\"chi_bar\"],\n",
    "                        \"smax_bar\": res[\"smax_bar\"],\n",
    "\n",
    "                        \"absorbed\": res[\"absorbed\"],\n",
    "                        \"absorb_state\": res[\"absorb_state\"],\n",
    "                        \"t_absorb\": res[\"t_absorb\"],\n",
    "                        \"n_steps_executed\": res[\"n_steps_executed\"],\n",
    "\n",
    "                        \"cluster_samples_json\": json.dumps(res[\"cluster_samples\"]),\n",
    "                        \"cluster_sizes_window_json\": json.dumps(res[\"window_sizes_all\"]),\n",
    "                    })\n",
    "\n",
    "    per_run_df = pd.DataFrame(rows)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        per_run_df = add_strategy_short(per_run_df, col=\"strategy\")\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "    def pr_allC(x): return float(np.mean(x == \"allC\"))\n",
    "    def pr_allD(x): return float(np.mean(x == \"allD\"))\n",
    "\n",
    "    group_cols = [\"payoff\", \"network\", \"strategy\"]\n",
    "    if \"strategy_short\" in per_run_df.columns:\n",
    "        group_cols.append(\"strategy_short\")\n",
    "\n",
    "    summary_df = (\n",
    "        per_run_df.groupby(group_cols, as_index=False)\n",
    "        .agg(\n",
    "            mean_barC=(\"barC\", \"mean\"),\n",
    "            std_barC=(\"barC\", \"std\"),\n",
    "\n",
    "            mean_smax=(\"smax_bar\", \"mean\"),\n",
    "            std_smax=(\"smax_bar\", \"std\"),\n",
    "\n",
    "            mean_chi=(\"chi_bar\", \"mean\"),\n",
    "            std_chi=(\"chi_bar\", \"std\"),\n",
    "\n",
    "            Pr_allC=(\"absorb_state\", pr_allC),\n",
    "            Pr_allD=(\"absorb_state\", pr_allD),\n",
    "\n",
    "            mean_t_absorb=(\"t_absorb\", \"mean\"),\n",
    "            std_t_absorb=(\"t_absorb\", \"std\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    per_run_path = None\n",
    "    summ_path = None\n",
    "    if save:\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        per_run_path = os.path.join(outdir, \"per_run_revised.csv\")\n",
    "        summ_path = os.path.join(outdir, \"summary_revised.csv\")\n",
    "        per_run_df.to_csv(per_run_path, index=False)\n",
    "        summary_df.to_csv(summ_path, index=False)\n",
    "\n",
    "    return per_run_df, summary_df, per_run_path, summ_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7bb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Results/Result_RQ0/Result_Revised/per_run_revised.csv\n",
      "Saved: Results/Result_RQ0/Result_Revised/summary_revised.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payoff</th>\n",
       "      <th>network</th>\n",
       "      <th>strategy</th>\n",
       "      <th>strategy_short</th>\n",
       "      <th>mean_barC</th>\n",
       "      <th>std_barC</th>\n",
       "      <th>mean_smax</th>\n",
       "      <th>std_smax</th>\n",
       "      <th>mean_chi</th>\n",
       "      <th>std_chi</th>\n",
       "      <th>Pr_allC</th>\n",
       "      <th>Pr_allD</th>\n",
       "      <th>mean_t_absorb</th>\n",
       "      <th>std_t_absorb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Canonical</td>\n",
       "      <td>ER_p0.02</td>\n",
       "      <td>ImitationStrategy</td>\n",
       "      <td>Imitate</td>\n",
       "      <td>0.039699</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>0.008674</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>1.397355</td>\n",
       "      <td>0.126658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1868.5</td>\n",
       "      <td>500.458049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Canonical</td>\n",
       "      <td>ER_p0.02</td>\n",
       "      <td>RLStrategy</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.050174</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007668</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>1.094946</td>\n",
       "      <td>0.080492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canonical</td>\n",
       "      <td>ER_p0.02</td>\n",
       "      <td>TitForTatStrategy</td>\n",
       "      <td>TFT</td>\n",
       "      <td>0.513625</td>\n",
       "      <td>0.084657</td>\n",
       "      <td>0.489875</td>\n",
       "      <td>0.093665</td>\n",
       "      <td>1.132198</td>\n",
       "      <td>0.335899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canonical</td>\n",
       "      <td>Grid_20x20</td>\n",
       "      <td>ImitationStrategy</td>\n",
       "      <td>Imitate</td>\n",
       "      <td>0.054265</td>\n",
       "      <td>0.014253</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>1.203856</td>\n",
       "      <td>0.140316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1801.0</td>\n",
       "      <td>607.205867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canonical</td>\n",
       "      <td>Grid_20x20</td>\n",
       "      <td>RLStrategy</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.049896</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.838301</td>\n",
       "      <td>0.126375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      payoff     network           strategy strategy_short  mean_barC  \\\n",
       "0  Canonical    ER_p0.02  ImitationStrategy        Imitate   0.039699   \n",
       "1  Canonical    ER_p0.02         RLStrategy             RL   0.050174   \n",
       "2  Canonical    ER_p0.02  TitForTatStrategy            TFT   0.513625   \n",
       "3  Canonical  Grid_20x20  ImitationStrategy        Imitate   0.054265   \n",
       "4  Canonical  Grid_20x20         RLStrategy             RL   0.049896   \n",
       "\n",
       "   std_barC  mean_smax  std_smax  mean_chi   std_chi  Pr_allC   Pr_allD  \\\n",
       "0  0.011157   0.008674  0.000923  1.397355  0.126658      0.0  0.066667   \n",
       "1  0.000598   0.007668  0.000192  1.094946  0.080492      0.0  0.000000   \n",
       "2  0.084657   0.489875  0.093665  1.132198  0.335899      0.0  0.000000   \n",
       "3  0.014253   0.008224  0.001001  1.203856  0.140316      0.0  0.100000   \n",
       "4  0.000380   0.005116  0.000063  0.838301  0.126375      0.0  0.000000   \n",
       "\n",
       "   mean_t_absorb  std_t_absorb  \n",
       "0         1868.5    500.458049  \n",
       "1         2000.0      0.000000  \n",
       "2         2000.0      0.000000  \n",
       "3         1801.0    607.205867  \n",
       "4         2000.0      0.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "networks_revised = [\n",
    "    (\"Grid_20x20\", dict(kind=\"grid\", n=400, graph_kwargs={\"periodic\": False})),\n",
    "    (\"ER_p0.02\",   dict(kind=\"erdos_renyi\", n=400, p=0.02)),  \n",
    "    #(\"WS_k8_p0.05\",dict(kind=\"watts_strogatz\", n=400, k=8, p=0.05)), \n",
    "    (\"WS_k8_p0.1\",dict(kind=\"watts_strogatz\", n=400, k=8, p=0.1)), \n",
    "    #(\"WS_k8_p0.5\",dict(kind=\"watts_strogatz\", n=400, k=8, p=0.5)), \n",
    "\n",
    "]\n",
    "\n",
    "strategies_revised = [\n",
    "    (\"ImitationStrategy\", ImitationStrategy),\n",
    "    (\"TitForTatStrategy\", TitForTatStrategy),\n",
    "    (\"RLStrategy\", ReinforcementLearningStrategy),\n",
    "]\n",
    "\n",
    "# change for different payoff matrices (Fixed matrices or tunable Tempation)\n",
    "#T_values = np.linspace(1.00, 2.00, 21)\n",
    "#payoff_mats_revised = make_payoff_grid(T_values)\n",
    "\n",
    "\n",
    "per_run_revised, summary_revised, per_run_path, summ_path = evaluate_revised_plan(\n",
    "    networks=networks_revised,\n",
    "    strategies=strategies_revised,\n",
    "    payoff_mats= payoff_matrices, # change payoff_mats_revised/payoff_matrices\n",
    "    runs=10,\n",
    "    steps=1000,\n",
    "    burn_in=500,\n",
    "    window=500,\n",
    "    seed0=2026,\n",
    "    outdir=\"Results/Result_RQ0/Result_Revised\",\n",
    "    save=True,\n",
    ")\n",
    "\n",
    "print(\"Saved:\", per_run_path)\n",
    "print(\"Saved:\", summ_path)\n",
    "\n",
    "summary_revised.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4aec75",
   "metadata": {},
   "source": [
    "### Find Tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_T(payoff_name: str) -> float:\n",
    "    m = re.search(r\"([0-9]+(?:\\.[0-9]+)?)\", str(payoff_name))\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse T from payoff name: {payoff_name}\")\n",
    "    return float(m.group(1))\n",
    "\n",
    "\n",
    "def estimate_Tc_from_curve(T, y, method=\"peak\"):\n",
    "    \"\"\"\n",
    "    T: 1D array sorted ascending\n",
    "    y: 1D array same length (may contain nan)\n",
    "    \"\"\"\n",
    "    T = np.asarray(T, float)\n",
    "    y = np.asarray(y, float)\n",
    "\n",
    "    ok = np.isfinite(T) & np.isfinite(y)\n",
    "    T = T[ok]; y = y[ok]\n",
    "    if len(T) < 3:\n",
    "        return np.nan\n",
    "\n",
    "    order = np.argsort(T)\n",
    "    T = T[order]; y = y[order]\n",
    "\n",
    "    if method == \"peak\":\n",
    "        return float(T[np.nanargmax(y)])\n",
    "\n",
    "    if method == \"inflection_slope\":\n",
    "        # discrete derivative, pick largest slope location\n",
    "        dy = np.diff(y) / np.diff(T)\n",
    "        k = int(np.nanargmax(dy))\n",
    "        # Tc between T[k] and T[k+1]\n",
    "        return float(0.5 * (T[k] + T[k+1]))\n",
    "\n",
    "    if method.startswith(\"threshold:\"):\n",
    "        thr = float(method.split(\":\", 1)[1])\n",
    "        idx = np.where(y >= thr)[0]\n",
    "        return float(T[idx[0]]) if len(idx) else np.nan\n",
    "\n",
    "    raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "def find_Tc_table(summary_df):\n",
    "    df = summary_df.copy()\n",
    "    df[\"T\"] = df[\"payoff\"].map(extract_beta) # change T / beta\n",
    "\n",
    "    out = []\n",
    "    for (net, strat), g in df.groupby([\"network\", \"strategy\"]):\n",
    "        g = g.sort_values(\"T\")\n",
    "        T = g[\"T\"].to_numpy()\n",
    "\n",
    "        Tc_peak_chi = estimate_Tc_from_curve(T, g[\"mean_chi\"].to_numpy(), method=\"peak\")\n",
    "        Tc_inflect  = estimate_Tc_from_curve(T, g[\"mean_smax\"].to_numpy(), method=\"inflection_slope\")\n",
    "        \n",
    "\n",
    "        # choose thresholds you like (example)\n",
    "        Tc_thr_C    = estimate_Tc_from_curve(T, g[\"mean_barC\"].to_numpy(), method=\"threshold:0.5\")\n",
    "        Tc_thr_Smax = estimate_Tc_from_curve(T, g[\"mean_smax\"].to_numpy(), method=\"threshold:0.2\")\n",
    "\n",
    "        out.append({\n",
    "            \"network\": net,\n",
    "            \"strategy\": strat,\n",
    "            \"Tc_peak_chi\": Tc_peak_chi,\n",
    "            \"Tc_inflect_smax\": Tc_inflect,\n",
    "            \"Tc_C>=0.5\": Tc_thr_C,\n",
    "            \"Tc_Smax>=0.2\": Tc_thr_Smax,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f094fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tc_df = find_Tc_table(summary_revised)\n",
    "Tc_df.to_csv(\"Result_RQ0/Result_revised/Tc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff659d",
   "metadata": {},
   "source": [
    "### Find Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved payoff meta: Results/Result_RQ0/Result_V7_Beta/payoff_meta_beta.csv\n",
      "Saved: Results/Result_RQ0/Result_V7_Beta/per_run_revised.csv\n",
      "Saved: Results/Result_RQ0/Result_V7_Beta/summary_revised.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payoff</th>\n",
       "      <th>network</th>\n",
       "      <th>strategy</th>\n",
       "      <th>strategy_short</th>\n",
       "      <th>mean_barC</th>\n",
       "      <th>std_barC</th>\n",
       "      <th>mean_smax</th>\n",
       "      <th>std_smax</th>\n",
       "      <th>mean_chi</th>\n",
       "      <th>std_chi</th>\n",
       "      <th>Pr_allC</th>\n",
       "      <th>Pr_allD</th>\n",
       "      <th>mean_t_absorb</th>\n",
       "      <th>std_t_absorb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beta_0.00</td>\n",
       "      <td>ER_k4</td>\n",
       "      <td>ImitationStrategy</td>\n",
       "      <td>Imitate</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.116571</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>401.2</td>\n",
       "      <td>515.364984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beta_0.00</td>\n",
       "      <td>Grid_6x6</td>\n",
       "      <td>ImitationStrategy</td>\n",
       "      <td>Imitate</td>\n",
       "      <td>0.261111</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beta_0.00</td>\n",
       "      <td>WS_k4_p0.1</td>\n",
       "      <td>ImitationStrategy</td>\n",
       "      <td>Imitate</td>\n",
       "      <td>0.252778</td>\n",
       "      <td>0.041821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beta_0.50</td>\n",
       "      <td>ER_k4</td>\n",
       "      <td>ImitationStrategy</td>\n",
       "      <td>Imitate</td>\n",
       "      <td>0.146367</td>\n",
       "      <td>0.067784</td>\n",
       "      <td>0.035361</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.424264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>203.4</td>\n",
       "      <td>419.850291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beta_0.50</td>\n",
       "      <td>Grid_6x6</td>\n",
       "      <td>ImitationStrategy</td>\n",
       "      <td>Imitate</td>\n",
       "      <td>0.162629</td>\n",
       "      <td>0.028089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.663330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      payoff     network           strategy strategy_short  mean_barC  \\\n",
       "0  beta_0.00       ER_k4  ImitationStrategy        Imitate   0.166667   \n",
       "1  beta_0.00    Grid_6x6  ImitationStrategy        Imitate   0.261111   \n",
       "2  beta_0.00  WS_k4_p0.1  ImitationStrategy        Imitate   0.252778   \n",
       "3  beta_0.50       ER_k4  ImitationStrategy        Imitate   0.146367   \n",
       "4  beta_0.50    Grid_6x6  ImitationStrategy        Imitate   0.162629   \n",
       "\n",
       "   std_barC  mean_smax  std_smax  mean_chi   std_chi  Pr_allC  Pr_allD  \\\n",
       "0  0.116571   0.027778  0.000000       0.0  0.000000      0.0      0.6   \n",
       "1  0.049777        NaN       NaN       NaN       NaN      0.0      1.0   \n",
       "2  0.041821        NaN       NaN       NaN       NaN      0.0      1.0   \n",
       "3  0.067784   0.035361  0.010724       0.3  0.424264      0.0      0.8   \n",
       "4  0.028089        NaN       NaN       NaN       NaN      0.0      1.0   \n",
       "\n",
       "   mean_t_absorb  std_t_absorb  \n",
       "0          401.2    515.364984  \n",
       "1            2.0      0.000000  \n",
       "2            2.0      0.000000  \n",
       "3          203.4    419.850291  \n",
       "4            4.9      1.663330  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Prison import PayoffMatrix\n",
    "\n",
    "n_nodes = 36\n",
    "kbar_target = 4.0\n",
    "\n",
    "networks_revised = [\n",
    "    # Grid: interior degree=4, boundary smaller (so avg degree slightly < 4 if periodic=False)\n",
    "    (\"Grid_6x6\", dict(kind=\"grid\", n=n_nodes, graph_kwargs={\"periodic\": False})),\n",
    "\n",
    "    # ER: choose p so E[k] ~ p*(n-1) = 4\n",
    "    (\"ER_k4\", dict(kind=\"erdos_renyi\", n=n_nodes, graph_kwargs={\"p\": kbar_target / (n_nodes - 1)})),\n",
    "\n",
    "    # WS: ring lattice degree k=4, then rewire with some p\n",
    "    #(\"WS_k4_p0.05\", dict(kind=\"watts_strogatz\", n=n_nodes, graph_kwargs={\"k\": 4, \"p\": 0.05})),\n",
    "    (\"WS_k4_p0.1\", dict(kind=\"watts_strogatz\", n=n_nodes, graph_kwargs={\"k\": 4, \"p\": 0.1})),\n",
    "]\n",
    "\n",
    "strategies_revised = [\n",
    "    (\"ImitationStrategy\", ImitationStrategy),\n",
    "    (\"TitForTatStrategy\", TitForTatStrategy),\n",
    "    (\"RLStrategy\", ReinforcementLearningStrategy),\n",
    "]\n",
    "\n",
    "# beta series \n",
    "beta_values = np.linspace(0.00, 5.00, 11)\n",
    "payoff_revised = PayoffMatrix(beta_values=beta_values, kbar=kbar_target, c=1.0)\n",
    "\n",
    "\n",
    "outdir = \"Results/Result_RQ0/Result_V7_Beta\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "payoff_meta_path = os.path.join(outdir, \"payoff_meta_beta.csv\")\n",
    "payoff_revised.meta.to_csv(payoff_meta_path, index=False)\n",
    "print(\"Saved payoff meta:\", payoff_meta_path)\n",
    "\n",
    "\n",
    "per_run_revised, summary_revised, per_run_path, summ_path = evaluate_revised_plan(\n",
    "    networks=networks_revised,\n",
    "    strategies=strategies_revised,\n",
    "    payoff_mats=payoff_revised.matrices,\n",
    "    runs=10,\n",
    "    steps=1000,\n",
    "    burn_in=500,\n",
    "    window=500,\n",
    "    seed0=2026,\n",
    "    outdir=outdir,\n",
    "    save=True,\n",
    ")\n",
    "\n",
    "print(\"Saved:\", per_run_path)\n",
    "print(\"Saved:\", summ_path)\n",
    "\n",
    "summary_revised.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_beta(payoff_name: str) -> float:\n",
    "    \"\"\"\n",
    "    payoff_name like 'beta_0.50' or 'beta_1.20' -> 0.50, 1.20\n",
    "    \"\"\"\n",
    "    m = re.search(r\"([0-9]+(?:\\.[0-9]+)?)\", str(payoff_name))\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse beta from payoff name: {payoff_name}\")\n",
    "    return float(m.group(1))\n",
    "\n",
    "\n",
    "def smooth_1d(y: np.ndarray, window: int = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simple moving average smoothing. window must be odd.\n",
    "    If window <= 1, returns y unchanged.\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if window is None or window <= 1:\n",
    "        return y\n",
    "    if window % 2 == 0:\n",
    "        window += 1\n",
    "    k = window // 2\n",
    "    ypad = np.pad(y, (k, k), mode=\"edge\")\n",
    "    kernel = np.ones(window, dtype=float) / window\n",
    "    return np.convolve(ypad, kernel, mode=\"valid\")\n",
    "\n",
    "\n",
    "def first_crossing_x(x: np.ndarray, y: np.ndarray, thr: float):\n",
    "    \"\"\"\n",
    "    Return x where y crosses thr (linear interpolation).\n",
    "    If never crosses, return np.nan.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if len(x) < 2:\n",
    "        return np.nan\n",
    "\n",
    "    s = y - thr\n",
    "    for i in range(len(s) - 1):\n",
    "        if (s[i] == 0):\n",
    "            return float(x[i])\n",
    "        if (s[i] < 0 and s[i + 1] > 0) or (s[i] > 0 and s[i + 1] < 0):\n",
    "            # linear interpolation between i and i+1\n",
    "            x0, x1 = x[i], x[i + 1]\n",
    "            y0, y1 = s[i], s[i + 1]\n",
    "            if y1 == y0:\n",
    "                return float(x0)\n",
    "            return float(x0 + (0 - y0) * (x1 - x0) / (y1 - y0))\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def argmax_x(x: np.ndarray, y: np.ndarray):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if len(x) == 0:\n",
    "        return np.nan\n",
    "    return float(x[int(np.nanargmax(y))])\n",
    "\n",
    "\n",
    "def inflection_x(x: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Estimate inflection as location of maximum absolute slope (finite difference).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if len(x) < 3:\n",
    "        return np.nan\n",
    "    dy = np.gradient(y, x)\n",
    "    idx = int(np.nanargmax(np.abs(dy)))\n",
    "    return float(x[idx])\n",
    "\n",
    "\n",
    "def midpoint_x(x: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Midpoint defined as crossing of (min(y)+max(y))/2.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if len(x) < 2:\n",
    "        return np.nan\n",
    "    y_min = np.nanmin(y)\n",
    "    y_max = np.nanmax(y)\n",
    "    mid = 0.5 * (y_min + y_max)\n",
    "    return first_crossing_x(x, y, mid)\n",
    "\n",
    "\n",
    "def estimate_beta_c_from_curves(\n",
    "    beta: np.ndarray,\n",
    "    mean_chi: np.ndarray,\n",
    "    mean_smax: np.ndarray,\n",
    "    mean_barC: np.ndarray = None,\n",
    "    smooth_window: int = 3,\n",
    "    thr_C: float = 0.5,\n",
    "    thr_Smax: float = 0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a dict of beta_c estimates using multiple criteria.\n",
    "    \"\"\"\n",
    "\n",
    "    beta = np.asarray(beta, dtype=float)\n",
    "    chi = np.asarray(mean_chi, dtype=float)\n",
    "    smax = np.asarray(mean_smax, dtype=float)\n",
    "\n",
    "    order = np.argsort(beta)\n",
    "    beta = beta[order]\n",
    "    chi = chi[order]\n",
    "    smax = smax[order]\n",
    "\n",
    "    if mean_barC is not None:\n",
    "        barC = np.asarray(mean_barC, dtype=float)[order]\n",
    "    else:\n",
    "        barC = None\n",
    "\n",
    "    chi_s = smooth_1d(chi, window=smooth_window)\n",
    "    smax_s = smooth_1d(smax, window=smooth_window)\n",
    "    barC_s = smooth_1d(barC, window=smooth_window) if barC is not None else None\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    # 1) peak of chi\n",
    "    out[\"beta_c_peak_chi\"] = argmax_x(beta, chi_s)\n",
    "\n",
    "    # 2) inflection (max slope) of smax\n",
    "    out[\"beta_c_inflect_smax\"] = inflection_x(beta, smax_s)\n",
    "\n",
    "    # 3) midpoint crossing of smax\n",
    "    out[\"beta_c_mid_smax\"] = midpoint_x(beta, smax_s)\n",
    "\n",
    "    # 4) threshold crossings (user-chosen)\n",
    "    if barC_s is not None:\n",
    "        out[\"beta_c_thr_C\"] = first_crossing_x(beta, barC_s, thr_C)\n",
    "    else:\n",
    "        out[\"beta_c_thr_C\"] = np.nan\n",
    "\n",
    "    out[\"beta_c_thr_Smax\"] = first_crossing_x(beta, smax_s, thr_Smax)\n",
    "\n",
    "\n",
    "    out[\"beta_min\"] = float(np.min(beta)) if len(beta) else np.nan\n",
    "    out[\"beta_max\"] = float(np.max(beta)) if len(beta) else np.nan\n",
    "    out[\"chi_peak\"] = float(np.nanmax(chi_s)) if len(beta) else np.nan\n",
    "    out[\"smax_min\"] = float(np.nanmin(smax_s)) if len(beta) else np.nan\n",
    "    out[\"smax_max\"] = float(np.nanmax(smax_s)) if len(beta) else np.nan\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_beta_c_table(\n",
    "    summary_df: pd.DataFrame,\n",
    "    group_cols=(\"network\", \"strategy\"),\n",
    "    payoff_col=\"payoff\",\n",
    "    mean_chi_col=\"mean_chi\",\n",
    "    mean_smax_col=\"mean_smax\",\n",
    "    mean_barC_col=\"mean_barC\",\n",
    "    smooth_window=3,\n",
    "    thr_C=0.5,\n",
    "    thr_Smax=0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    summary_df must have:\n",
    "      payoff (e.g., 'beta_0.50')\n",
    "      mean_chi, mean_smax (and optionally mean_barC)\n",
    "      plus grouping columns like network, strategy.\n",
    "    \"\"\"\n",
    "\n",
    "    df = summary_df.copy()\n",
    "\n",
    "    # parse beta from payoff name\n",
    "    df[\"beta\"] = df[payoff_col].map(extract_beta)\n",
    "\n",
    "    # sanity: ensure required cols exist\n",
    "    for c in [mean_chi_col, mean_smax_col]:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"summary_df missing required column: {c}\")\n",
    "\n",
    "    have_barC = mean_barC_col in df.columns\n",
    "\n",
    "    rows = []\n",
    "    for keys, g in df.groupby(list(group_cols), dropna=False):\n",
    "        if not isinstance(keys, tuple):\n",
    "            keys = (keys,)\n",
    "\n",
    "        beta = g[\"beta\"].to_numpy()\n",
    "        mean_chi = g[mean_chi_col].to_numpy()\n",
    "        mean_smax = g[mean_smax_col].to_numpy()\n",
    "        mean_barC = g[mean_barC_col].to_numpy() if have_barC else None\n",
    "\n",
    "        est = estimate_beta_c_from_curves(\n",
    "            beta=beta,\n",
    "            mean_chi=mean_chi,\n",
    "            mean_smax=mean_smax,\n",
    "            mean_barC=mean_barC,\n",
    "            smooth_window=smooth_window,\n",
    "            thr_C=thr_C,\n",
    "            thr_Smax=thr_Smax,\n",
    "        )\n",
    "\n",
    "        row = {col: val for col, val in zip(group_cols, keys)}\n",
    "        row.update(est)\n",
    "        rows.append(row)\n",
    "\n",
    "    out = pd.DataFrame(rows).sort_values(list(group_cols)).reset_index(drop=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba682dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "summary_revised = pd.read_csv(\"Results/Result_RQ0/Result_V7_beta/summary_revised.csv\")\n",
    "\n",
    "beta_c_df = compute_beta_c_table(\n",
    "    summary_revised,                    \n",
    "    group_cols=(\"network\", \"strategy\"),\n",
    "    payoff_col=\"payoff\",\n",
    "    mean_chi_col=\"mean_chi\",\n",
    "    mean_smax_col=\"mean_smax\",\n",
    "    mean_barC_col=\"mean_barC\",\n",
    "    smooth_window=3,\n",
    "    thr_C=0.5,\n",
    "    thr_Smax=0.2,\n",
    ")\n",
    "\n",
    "beta_c_df.to_csv(\"Results/Result_RQ0/Result_V7_Beta/beta_c.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b3d25",
   "metadata": {},
   "source": [
    "### Line Plots (for continous condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGDIR = Path(\"Results/Result_RQ0/Result_V7_Beta/Figures_Revised\")\n",
    "FIGDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def show_saved(fig, fname, dpi=200, close=True):\n",
    "    \"\"\"\n",
    "    Option A: savefig + display image file (robust in VS Code notebooks).\n",
    "    \"\"\"\n",
    "    path = FIGDIR / fname\n",
    "    fig.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    if close:\n",
    "        plt.close(fig)\n",
    "    display(Image(filename=str(path)))\n",
    "    return str(path)\n",
    "\n",
    "# =========================\n",
    "# 1) Load data\n",
    "# =========================\n",
    "### for Tc\n",
    "#summary = pd.read_csv(\"Result_RQ0/Result_S1/Result_Revised/summary_revised.csv\")\n",
    "#per_run = pd.read_csv(\"Result_RQ0/Result_S1/Result_Revised/per_run_revised.csv\")\n",
    "#tc = pd.read_csv(\"Result_RQ0/Result_S1/Result_Revised/Tc.csv\")\n",
    "\n",
    "### for Beta\n",
    "summary = pd.read_csv(\"Results/Result_RQ0/Result_V7_Beta/summary_revised.csv\")\n",
    "per_run = pd.read_csv(\"Results/Result_RQ0/Result_V7_Beta/per_run_revised.csv\")\n",
    "meta = pd.read_csv(\"Results/Result_RQ0/Result_V7_Beta/payoff_meta_beta.csv\")\n",
    "#tc   = pd.read_csv(\"Results/Result_RQ0/Result_V7_Beta/beta_c.csv\")\n",
    "\n",
    "    \n",
    "# -------------------------\n",
    "# 2) Parse T from payoff name\n",
    "# -------------------------\n",
    "#def parse_T(payoff_str):\n",
    "#    \"\"\"\n",
    "#    Extract first float-like number from the payoff string.\n",
    "#    Works for names like: \"T=1.20\", \"T_1.2\", \"1.2\", \"Temptation=1.2\", etc.\n",
    "#    \"\"\"\n",
    "#   s = str(payoff_str)\n",
    "#   m = re.search(r\"(\\d+(\\.\\d+)?)\", s)\n",
    "#   return float(m.group(1)) if m else np.nan\n",
    "\n",
    "#for df in (summary, per_run, tc):\n",
    "#    if \"payoff\" in df.columns:\n",
    "#        df[\"T\"] = df[\"payoff\"].map(parse_T)\n",
    "#   elif \"T\" not in df.columns:\n",
    "#       # if Tc.csv already has T columns only, leave it\n",
    "#       pass\n",
    "## Ensure sorting\n",
    "#summary = summary.sort_values([\"strategy\", \"network\", \"T\"]).reset_index(drop=True)\n",
    "#per_run = per_run.sort_values([\"strategy\", \"network\", \"T\"]).reset_index(drop=True)\n",
    "\n",
    "# -------------------------\n",
    "# 2) Map beta from payoff name using payoff_meta_beta.csv\n",
    "# -------------------------\n",
    "payoff_to_beta = dict(zip(meta[\"payoff\"], meta[\"beta\"]))\n",
    "\n",
    "for df in (summary, per_run):\n",
    "    df[\"T\"] = df[\"payoff\"].map(payoff_to_beta)  # keep column name \"T\" so your code doesn't change\n",
    "\n",
    "summary = summary.sort_values([\"strategy\", \"network\", \"T\"]).reset_index(drop=True)\n",
    "per_run = per_run.sort_values([\"strategy\", \"network\", \"T\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) Small helpers\n",
    "# =========================\n",
    "def short_strategy(name):\n",
    "    s = str(name)\n",
    "    if \"TitForTat\" in s or \"Tit For Tat\" in s:\n",
    "        return \"TFT\"\n",
    "    if \"Imitation\" in s:\n",
    "        return \"Imitate\"\n",
    "    return s\n",
    "\n",
    "summary[\"strategy_short\"] = summary[\"strategy\"].map(short_strategy) if \"strategy\" in summary else \"Strategy\"\n",
    "per_run[\"strategy_short\"] = per_run[\"strategy\"].map(short_strategy) if \"strategy\" in per_run else \"Strategy\"\n",
    "\n",
    "def unique_levels(df, col):\n",
    "    return [x for x in df[col].dropna().unique().tolist()]\n",
    "\n",
    "strategies = unique_levels(summary, \"strategy\") if \"strategy\" in summary else unique_levels(per_run, \"strategy\")\n",
    "networks = unique_levels(summary, \"network\") if \"network\" in summary else unique_levels(per_run, \"network\")\n",
    "\n",
    "# =========================\n",
    "# 4) Core plots (phase curves)\n",
    "# =========================\n",
    "def plot_barC_by_T(summary_df, networks=None, strategies=None):\n",
    "    \"\"\"\n",
    "    mean_barC(T) with error bars (std_barC) for each network, one panel per strategy.\n",
    "    \"\"\"\n",
    "    networks = networks or unique_levels(summary_df, \"network\")\n",
    "    strategies = strategies or unique_levels(summary_df, \"strategy\")\n",
    "\n",
    "    for strat in strategies:\n",
    "        sub = summary_df[summary_df[\"strategy\"] == strat].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        # Create one row of subplots (one per network)\n",
    "        ncols = len(networks)\n",
    "        fig, axes = plt.subplots(1, ncols, figsize=(4*ncols, 3), sharey=True)\n",
    "        if ncols == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for ax, net in zip(axes, networks):\n",
    "            tmp = sub[sub[\"network\"] == net].sort_values(\"T\")\n",
    "            if tmp.empty:\n",
    "                ax.set_title(net + \" (no data)\")\n",
    "                continue\n",
    "\n",
    "            x = tmp[\"T\"].to_numpy()\n",
    "            y = tmp[\"mean_barC\"].to_numpy()\n",
    "            yerr = tmp[\"std_barC\"].to_numpy() if \"std_barC\" in tmp else None\n",
    "\n",
    "            ax.errorbar(x, y, yerr=yerr, marker=\"o\", linewidth=1, capsize=3)\n",
    "            ax.set_title(net)\n",
    "            ax.set_xlabel(\"beta\") # change T / beta\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        axes[0].set_ylabel(\"Mean cooperation (barC)\")\n",
    "        fig.suptitle(f\"barC vs beta  {short_strategy(strat)}\", y=1.05) # change T / beta\n",
    "        fig.tight_layout()\n",
    "        show_saved(fig, f\"barC_vs_beta__{short_strategy(strat)}.png\") # change T / beta\n",
    "\n",
    "\n",
    "def plot_fixation_probs(summary_df, networks=None, strategies=None):\n",
    "    \"\"\"\n",
    "    Pr_allC(T) and Pr_allD(T) for each network, one panel per strategy.\n",
    "    \"\"\"\n",
    "    networks = networks or unique_levels(summary_df, \"network\")\n",
    "    strategies = strategies or unique_levels(summary_df, \"strategy\")\n",
    "\n",
    "    for strat in strategies:\n",
    "        sub = summary_df[summary_df[\"strategy\"] == strat].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        ncols = len(networks)\n",
    "        fig, axes = plt.subplots(1, ncols, figsize=(4*ncols, 3), sharey=True)\n",
    "        if ncols == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for ax, net in zip(axes, networks):\n",
    "            tmp = sub[sub[\"network\"] == net].sort_values(\"T\")\n",
    "            if tmp.empty:\n",
    "                ax.set_title(net + \" (no data)\")\n",
    "                continue\n",
    "\n",
    "            x = tmp[\"T\"].to_numpy()\n",
    "            yC = tmp[\"Pr_allC\"].to_numpy() if \"Pr_allC\" in tmp else None\n",
    "            yD = tmp[\"Pr_allD\"].to_numpy() if \"Pr_allD\" in tmp else None\n",
    "\n",
    "            if yC is not None:\n",
    "                ax.plot(x, yC, marker=\"o\", linewidth=1, label=\"Pr(all-C)\")\n",
    "            if yD is not None:\n",
    "                ax.plot(x, yD, marker=\"o\", linewidth=1, label=\"Pr(all-D)\")\n",
    "\n",
    "            ax.set_title(net)\n",
    "            ax.set_xlabel(\"beta\") # change T / beta\n",
    "            ax.set_ylim(-0.05, 1.05)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(loc=\"best\", fontsize=8)\n",
    "\n",
    "        axes[0].set_ylabel(\"Fixation probability\")\n",
    "        fig.suptitle(f\"Fixation vs beta  {short_strategy(strat)}\", y=1.05) # change T / beta\n",
    "        fig.tight_layout()\n",
    "        show_saved(fig, f\"fixation_vs_beta__{short_strategy(strat)}.png\") # change T / beta\n",
    "\n",
    "def plot_absorption_time(summary_df, networks=None, strategies=None):\n",
    "    \"\"\"\n",
    "    mean_t_absorb(T) with error bars (std_t_absorb) for each network, one panel per strategy.\n",
    "    \"\"\"\n",
    "    networks = networks or unique_levels(summary_df, \"network\")\n",
    "    strategies = strategies or unique_levels(summary_df, \"strategy\")\n",
    "\n",
    "    for strat in strategies:\n",
    "        sub = summary_df[summary_df[\"strategy\"] == strat].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        ncols = len(networks)\n",
    "        fig, axes = plt.subplots(1, ncols, figsize=(4*ncols, 3), sharey=True)\n",
    "        if ncols == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for ax, net in zip(axes, networks):\n",
    "            tmp = sub[sub[\"network\"] == net].sort_values(\"T\")\n",
    "            if tmp.empty:\n",
    "                ax.set_title(net + \" (no data)\")\n",
    "                continue\n",
    "\n",
    "            x = tmp[\"T\"].to_numpy()\n",
    "            y = tmp[\"mean_t_absorb\"].to_numpy() if \"mean_t_absorb\" in tmp else None\n",
    "            yerr = tmp[\"std_t_absorb\"].to_numpy() if \"std_t_absorb\" in tmp else None\n",
    "\n",
    "            ax.errorbar(x, y, yerr=yerr, marker=\"o\", linewidth=1, capsize=3)\n",
    "            ax.set_title(net)\n",
    "            ax.set_xlabel(\"beta\") # change T / beta\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        axes[0].set_ylabel(\"Mean time to absorption\")\n",
    "        fig.suptitle(f\"Absorption time vs beta  {short_strategy(strat)}\", y=1.05) # change T / beta\n",
    "        fig.tight_layout()\n",
    "        show_saved(fig, f\"t_absorb_vs_beta__{short_strategy(strat)}.png\") # change T / beta\n",
    "\n",
    "# =========================\n",
    "# 5) Percolation-style plots (Smax and chi) + Tc markers\n",
    "# =========================\n",
    "def add_Tc_lines(ax, tc_sub):\n",
    "    \"\"\"\n",
    "    Draw vertical lines for any Tc columns present in Tc.csv\n",
    "    \"\"\"\n",
    "    if tc_sub.empty:\n",
    "        return\n",
    "    # common names you might have used\n",
    "    ## for Tc\n",
    "    #candidate_cols = [\n",
    "    #    \"Tc_peak_chi\", \"Tc_inflect_smax\", \"Tc_mid_smax\", \"Tc_threshold_barC\", \"Tc_threshold_smax\"\n",
    "    #]\n",
    "\n",
    "    ## for Beta\n",
    "    candidate_cols = [\n",
    "    \"beta_c_peak_chi\",\n",
    "    \"beta_c_inflect_smax\",\n",
    "    \"beta_c_mid_smax\",\n",
    "    \"beta_c_thr_C\",\n",
    "    \"beta_c_thr_Smax\",\n",
    "]\n",
    "\n",
    "    for c in candidate_cols:\n",
    "        if c in tc_sub.columns:\n",
    "            val = tc_sub[c].iloc[0]\n",
    "            if pd.notna(val):\n",
    "                ax.axvline(val, linestyle=\"--\", linewidth=1, label=c)\n",
    "\n",
    "def plot_Smax_and_chi(summary_df, tc_df, networks=None, strategies=None):\n",
    "    \"\"\"\n",
    "    For each (strategy, network): plot mean_smax(T) and mean_chi(T) if available,\n",
    "    and overlay Tc estimates from Tc.csv.\n",
    "    \"\"\"\n",
    "    networks = networks or unique_levels(summary_df, \"network\")\n",
    "    strategies = strategies or unique_levels(summary_df, \"strategy\")\n",
    "\n",
    "    has_smax = \"mean_smax\" in summary_df.columns\n",
    "    has_chi  = \"mean_chi\" in summary_df.columns\n",
    "\n",
    "    if not (has_smax or has_chi):\n",
    "        print(\"summary_revised.csv has no mean_smax/mean_chi columns; skipping Smax/chi plots.\")\n",
    "        return\n",
    "\n",
    "    for strat in strategies:\n",
    "        for net in networks:\n",
    "            tmp = summary_df[(summary_df[\"strategy\"] == strat) & (summary_df[\"network\"] == net)].sort_values(\"T\")\n",
    "            if tmp.empty:\n",
    "                continue\n",
    "\n",
    "            # find Tc row if it exists\n",
    "            tc_sub = tc_df.copy()\n",
    "            if \"strategy\" in tc_sub.columns:\n",
    "                tc_sub = tc_sub[tc_sub[\"strategy\"] == strat]\n",
    "            if \"network\" in tc_sub.columns:\n",
    "                tc_sub = tc_sub[tc_sub[\"network\"] == net]\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "            x = tmp[\"T\"].to_numpy()\n",
    "\n",
    "            if has_smax and tmp[\"mean_smax\"].notna().any():\n",
    "                ax.plot(x, tmp[\"mean_smax\"].to_numpy(), marker=\"o\", linewidth=1, label=\"mean_smax\")\n",
    "\n",
    "            if has_chi and tmp[\"mean_chi\"].notna().any():\n",
    "                ax.plot(x, tmp[\"mean_chi\"].to_numpy(), marker=\"o\", linewidth=1, label=\"mean_chi\")\n",
    "\n",
    "            # add_Tc_lines(ax, tc_sub) # show the critical points or not\n",
    "\n",
    "            ax.set_title(f\"{net}  {short_strategy(strat)}\")\n",
    "            ax.set_xlabel(\"beta\")  # change T / beta\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(loc=\"best\", fontsize=8)\n",
    "\n",
    "            fig.tight_layout()\n",
    "            show_saved(fig, f\"Smax_chi__{net}__{short_strategy(strat)}.png\")\n",
    "\n",
    "# =========================\n",
    "# 6) Heatmap: mean_barC across (network x T), one heatmap per strategy\n",
    "# =========================\n",
    "def plot_heatmap_barC(summary_df):\n",
    "    \"\"\"\n",
    "    One heatmap per strategy: rows=network, cols=T, values=mean_barC.\n",
    "    \"\"\"\n",
    "    if \"mean_barC\" not in summary_df.columns:\n",
    "        print(\"No mean_barC in summary; skipping heatmap.\")\n",
    "        return\n",
    "\n",
    "    for strat in unique_levels(summary_df, \"strategy\"):\n",
    "        sub = summary_df[summary_df[\"strategy\"] == strat].copy()\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        pivot = sub.pivot_table(index=\"network\", columns=\"T\", values=\"mean_barC\", aggfunc=\"mean\")\n",
    "        pivot = pivot.sort_index(axis=0).sort_index(axis=1)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 3))\n",
    "        im = ax.imshow(pivot.to_numpy(dtype=float), aspect=\"auto\")\n",
    "\n",
    "        ax.set_yticks(range(pivot.shape[0]))\n",
    "        ax.set_yticklabels(pivot.index)\n",
    "\n",
    "        ax.set_xticks(range(pivot.shape[1]))\n",
    "        ax.set_xticklabels([f\"{t:.2f}\" for t in pivot.columns], rotation=30, ha=\"right\", size = 6)\n",
    "\n",
    "        ax.set_title(f\"Heatmap of mean_barC  {short_strategy(strat)}\")\n",
    "        ax.set_xlabel(\"beta\")  # change T / beta\n",
    "        ax.set_ylabel(\"Network\")\n",
    "\n",
    "        fig.colorbar(im, ax=ax, label=\"mean_barC\")\n",
    "        fig.tight_layout()\n",
    "        show_saved(fig, f\"heatmap_barC__{short_strategy(strat)}.png\")\n",
    "\n",
    "# =========================\n",
    "# 7) Survival curve (KaplanMeier style) for time-to-allD\n",
    "# =========================\n",
    "def km_survival(times, events):\n",
    "    \"\"\"\n",
    "    Simple KaplanMeier estimator.\n",
    "    times: array of durations\n",
    "    events: array of 1 (event occurred) or 0 (censored)\n",
    "    returns: t_unique, S(t)\n",
    "    \"\"\"\n",
    "    times = np.asarray(times, dtype=int)\n",
    "    events = np.asarray(events, dtype=int)\n",
    "\n",
    "    order = np.argsort(times)\n",
    "    times = times[order]\n",
    "    events = events[order]\n",
    "\n",
    "    uniq = np.unique(times)\n",
    "    n = len(times)\n",
    "    at_risk = n\n",
    "    S = 1.0\n",
    "    S_list = []\n",
    "    t_list = []\n",
    "\n",
    "    idx = 0\n",
    "    for t in uniq:\n",
    "        # all observations with this time\n",
    "        mask = (times == t)\n",
    "        d_i = events[mask].sum()          # number of events at t\n",
    "        n_i = mask.sum()                  # total at this time (events+censored)\n",
    "\n",
    "        if at_risk > 0:\n",
    "            if d_i > 0:\n",
    "                S *= (1.0 - d_i / at_risk)\n",
    "        t_list.append(t)\n",
    "        S_list.append(S)\n",
    "\n",
    "        at_risk -= n_i\n",
    "\n",
    "    return np.array(t_list), np.array(S_list)\n",
    "\n",
    "def plot_survival_allD(per_run_df, steps_cap=1000):\n",
    "    \"\"\"\n",
    "    Plot KM survival: P(not yet all-D by time t).\n",
    "    One figure per (network, strategy), with multiple T curves.\n",
    "    \"\"\"\n",
    "    if \"absorb_state\" not in per_run_df.columns:\n",
    "        print(\"No absorb_state in per_run; skipping survival plots.\")\n",
    "        return\n",
    "\n",
    "    for strat in unique_levels(per_run_df, \"strategy\"):\n",
    "        for net in unique_levels(per_run_df, \"network\"):\n",
    "            sub = per_run_df[(per_run_df[\"strategy\"] == strat) & (per_run_df[\"network\"] == net)].copy()\n",
    "            if sub.empty:\n",
    "                continue\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "            for T in sorted(sub[\"T\"].dropna().unique()):\n",
    "                tmp = sub[sub[\"T\"] == T]\n",
    "\n",
    "                # event: allD; censor otherwise (allC or None) at observed t_absorb\n",
    "                times = tmp[\"t_absorb\"].to_numpy(dtype=int)\n",
    "                events = (tmp[\"absorb_state\"].astype(str) == \"allD\").astype(int).to_numpy()\n",
    "\n",
    "                # if your pipeline uses steps_cap as \"no absorption\", KM naturally handles censoring\n",
    "                tt, SS = km_survival(times, events)\n",
    "                ax.step(tt, SS, where=\"post\", label=f\"beta={T:.2f}\") # change T/beta\n",
    "\n",
    "\n",
    "            ax.set_title(f\"Survival to all-D  {net}  {short_strategy(strat)}\")\n",
    "            ax.set_xlabel(\"t\")\n",
    "            ax.set_ylabel(\"P(not all-D yet)\")\n",
    "            ax.set_ylim(-0.05, 1.05)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(loc=\"best\", fontsize=7, ncol=2)\n",
    "\n",
    "            fig.tight_layout()\n",
    "            show_saved(fig, f\"survival_allD__{net}__{short_strategy(strat)}.png\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# 8) RUN ALL PLOTS\n",
    "# =========================\n",
    "plot_barC_by_T(summary, networks=networks, strategies=strategies)\n",
    "plot_fixation_probs(summary, networks=networks, strategies=strategies)\n",
    "plot_absorption_time(summary, networks=networks, strategies=strategies)\n",
    "\n",
    "plot_Smax_and_chi(summary, tc, networks=networks, strategies=strategies)\n",
    "plot_heatmap_barC(summary)\n",
    "\n",
    "plot_survival_allD(per_run, steps_cap=int(per_run[\"t_absorb\"].max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b374fd9",
   "metadata": {},
   "source": [
    "### Bar Plots (For Categorical condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f873aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "summary_df = pd.read_csv(\"Results/Result_RQ0/Result_V4/summary_revised.csv\")\n",
    "per_run_df = pd.read_csv(\"Results/Result_RQ0/Result_V4/per_run_revised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4415358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_strategy_short(df, col=\"strategy\"):\n",
    "    def short(s):\n",
    "        if \"ActionStrategy\" in s: return \"Action\"\n",
    "        if \"ImitationStrategy\" in s: return \"Imitate\"\n",
    "        if \"Fermi\" in s: return \"Fermi\"\n",
    "        if \"RLStrategy\" in s or \"Reinforcement\" in s: return \"RL\"\n",
    "        if \"TitForTat\" in s or \"Tit For Tat\" in s: return \"TFT\"\n",
    "        return re.sub(r\"\\(.*\\)\", \"\", s)  # fallback\n",
    "    df = df.copy()\n",
    "    df[\"strategy_short\"] = df[col].astype(str).map(short)\n",
    "    return df\n",
    "\n",
    "summary_df = add_strategy_short(summary_df, col=\"strategy\")\n",
    "per_run_df = add_strategy_short(per_run_df, col=\"strategy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e1feb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"figures\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "def show_saved(fig, filename, dpi=200):\n",
    "    path = os.path.join(OUTDIR, filename)\n",
    "    fig.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    display(Image(filename=path))\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_mean_barC_save(df, payoff_name, col=\"strategy\"):\n",
    "    sub = df[df[\"payoff\"] == payoff_name].copy()\n",
    "    if \"strategy_short\" in sub.columns:\n",
    "        col = \"strategy_short\"\n",
    "    mat = sub.pivot_table(index=\"network\", columns=col, values=\"mean_barC\", aggfunc=\"mean\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 4))\n",
    "    im = ax.imshow(mat.to_numpy(dtype=float), aspect=\"auto\")\n",
    "    fig.colorbar(im, ax=ax, label=\"mean_barC\")\n",
    "\n",
    "    ax.set_xticks(range(mat.shape[1]))\n",
    "    ax.set_xticklabels(mat.columns, rotation=30, ha=\"right\")\n",
    "    ax.set_yticks(range(mat.shape[0]))\n",
    "    ax.set_yticklabels(mat.index)\n",
    "    ax.set_title(f\"Mean cooperation (barC)  {payoff_name}\")\n",
    "\n",
    "    # annotate numbers\n",
    "    for i in range(mat.shape[0]):\n",
    "        for j in range(mat.shape[1]):\n",
    "            v = mat.iat[i, j]\n",
    "            if np.isfinite(v):\n",
    "                ax.text(j, i, f\"{v:.2f}\", ha=\"center\", va=\"center\", fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return show_saved(fig, f\"heatmap_{payoff_name}.png\")\n",
    "\n",
    "heatmap_mean_barC_save(summary_df, \"Default\")\n",
    "#heatmap_mean_barC_save(summary_df, \"Canonical\")\n",
    "heatmap_mean_barC_save(summary_df, \"Snowdrift\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_groupedbars_mean_barC(summary_df, payoff_name, use_short=True, colors=None):\n",
    "    sub = summary_df[summary_df[\"payoff\"] == payoff_name].copy()\n",
    "    strat_col = \"strategy_short\" if (use_short and \"strategy_short\" in sub.columns) else \"strategy\"\n",
    "\n",
    "    pivot = sub.pivot_table(index=\"network\", columns=strat_col, values=\"mean_barC\", aggfunc=\"mean\")\n",
    "    networks = list(pivot.index)\n",
    "    strategies = list(pivot.columns)\n",
    "\n",
    "    # default colors (OkabeIto)\n",
    "    if colors is None:\n",
    "        colors = {\n",
    "            \"Imitate\": \"#4E79A7\",\n",
    "            \"RL\":      \"#F28E2B\",\n",
    "            \"TFT\":     \"#59A14F\",\n",
    "            # if you use short names, include them too:\n",
    "            #\"Im\":      \"#0072B2\",\n",
    "        }\n",
    "\n",
    "    # fallback color cycle if some keys are missing\n",
    "    fallback = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "    x = np.arange(len(networks))\n",
    "    width = 0.6 / max(len(strategies), 1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    for k, s in enumerate(strategies):\n",
    "        c = colors.get(str(s), fallback[k % len(fallback)])\n",
    "        ax.bar(\n",
    "            x + (k - (len(strategies) - 1) / 2) * width,\n",
    "            pivot[s].values,\n",
    "            width,\n",
    "            label=str(s),\n",
    "            color=c,                    # <-- HERE\n",
    "            edgecolor=\"white\",\n",
    "            linewidth=0.8\n",
    "        )\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(networks, rotation=30, ha=\"right\")\n",
    "    ax.set_ylabel(\"mean_barC\")\n",
    "    ax.set_title(f\"Mean cooperation by network  strategy  {payoff_name}\")\n",
    "    ax.legend(ncols=min(4, len(strategies)), fontsize=8)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return show_saved(fig, f\"groupedbars_mean_barC_{payoff_name}.png\")\n",
    "\n",
    "plot_groupedbars_mean_barC(summary_df, \"Snowdrift\")\n",
    "plot_groupedbars_mean_barC(summary_df, \"Default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8494b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def violin_by_network_strategy(per_run_df, payoff_name, metric,\n",
    "                               use_short=True, logy=False, ylim=None):\n",
    "    sub = per_run_df[per_run_df[\"payoff\"] == payoff_name].copy()\n",
    "    strat_col = \"strategy_short\" if (use_short and \"strategy_short\" in sub.columns) else \"strategy\"\n",
    "\n",
    "    need = [\"network\", strat_col, metric]\n",
    "    for c in need:\n",
    "        if c not in sub.columns:\n",
    "            raise ValueError(f\"Missing column: {c}\")\n",
    "\n",
    "    networks = sorted(sub[\"network\"].unique())\n",
    "    strategies = sorted(sub[strat_col].unique())\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(networks), figsize=(4*len(networks), 4), sharey=True)\n",
    "    if len(networks) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, net in zip(axes, networks):\n",
    "        g = sub[sub[\"network\"] == net]\n",
    "\n",
    "        data = []\n",
    "        for s in strategies:\n",
    "            vals = g.loc[g[strat_col] == s, metric].dropna().to_numpy()\n",
    "            data.append(vals)\n",
    "\n",
    "        # violin\n",
    "        parts = ax.violinplot(data, showmeans=False, showmedians=True, showextrema=False)\n",
    "\n",
    "        # jittered points (helps see sample size / discreteness)\n",
    "        rng = np.random.default_rng(0)\n",
    "        for i, vals in enumerate(data, start=1):\n",
    "            if len(vals) == 0:\n",
    "                continue\n",
    "            x = i + rng.normal(0, 0.05, size=len(vals))\n",
    "            ax.scatter(x, vals, s=10, alpha=0.35)\n",
    "\n",
    "        ax.set_title(str(net))\n",
    "        ax.set_xticks(range(1, len(strategies)+1))\n",
    "        ax.set_xticklabels(strategies, rotation=30, ha=\"right\")\n",
    "\n",
    "        if logy:\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "        if ylim is not None:\n",
    "            ax.set_ylim(*ylim)\n",
    "\n",
    "        ax.grid(True, axis=\"y\", alpha=0.2)\n",
    "\n",
    "    fig.suptitle(f\"{metric} distribution (per run)  {payoff_name}\", y=1.02)\n",
    "    axes[0].set_ylabel(metric)\n",
    "    fig.tight_layout()\n",
    "    return show_saved(fig, f\"violin_{metric}_{payoff_name}.png\")\n",
    "\n",
    "# Examples:\n",
    "violin_by_network_strategy(per_run_df, \"Snowdrift\", metric=\"barC\", logy=False)\n",
    "violin_by_network_strategy(per_run_df, \"Snowdrift\", metric=\"t_absorb\", logy=True)\n",
    "violin_by_network_strategy(per_run_df, \"Default\", metric=\"barC\")\n",
    "violin_by_network_strategy(per_run_df, \"Default\", metric=\"t_absorb\", logy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0aedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probs_stacked(per_run_df, payoff_name, use_short=True, colors=None):\n",
    "    sub = per_run_df[per_run_df[\"payoff\"] == payoff_name].copy()\n",
    "    strat_col = \"strategy_short\" if (use_short and \"strategy_short\" in sub.columns) else \"strategy\"\n",
    "\n",
    "    for c in [\"network\", strat_col, \"absorbed\", \"absorb_state\"]:\n",
    "        if c not in sub.columns:\n",
    "            raise ValueError(f\"Missing column: {c}\")\n",
    "\n",
    "    # default colors (edit as you like)\n",
    "    if colors is None:\n",
    "        colors = {\n",
    "            \"allC\":   \"#6A92F6\",\n",
    "            \"allD\":   \"#FAC460\",\n",
    "            \"active\": \"#BAB0AC\",\n",
    "        }\n",
    "\n",
    "    rows = []\n",
    "    for (net, strat), g in sub.groupby([\"network\", strat_col]):\n",
    "        n = len(g)\n",
    "        kC = int((g[\"absorbed\"].astype(int).eq(1) & g[\"absorb_state\"].eq(\"allC\")).sum())\n",
    "        kD = int((g[\"absorbed\"].astype(int).eq(1) & g[\"absorb_state\"].eq(\"allD\")).sum())\n",
    "        pC = kC / n\n",
    "        pD = kD / n\n",
    "        pA = 1 - pC - pD\n",
    "        rows.append([net, strat, pC, pD, pA])\n",
    "\n",
    "    tab = pd.DataFrame(rows, columns=[\"network\", \"strategy\", \"p_allC\", \"p_allD\", \"p_active\"])\n",
    "\n",
    "    networks = sorted(tab[\"network\"].unique())\n",
    "    strategies = sorted(tab[\"strategy\"].unique())\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(networks), figsize=(4*len(networks), 4), sharey=True)\n",
    "    if len(networks) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, net in zip(axes, networks):\n",
    "        g = tab[tab[\"network\"] == net].set_index(\"strategy\").reindex(strategies)\n",
    "\n",
    "        x = np.arange(len(strategies))\n",
    "        ax.bar(x, g[\"p_allC\"], color=colors[\"allC\"], label=\"allC\", edgecolor=\"white\", linewidth=0.8)\n",
    "        ax.bar(x, g[\"p_allD\"], bottom=g[\"p_allC\"], color=colors[\"allD\"], label=\"allD\", edgecolor=\"white\", linewidth=0.8)\n",
    "        ax.bar(x, g[\"p_active\"],\n",
    "               bottom=g[\"p_allC\"] + g[\"p_allD\"],\n",
    "               color=colors[\"active\"], label=\"not absorbed\",\n",
    "               edgecolor=\"white\", linewidth=0.8\n",
    "               )\n",
    "\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(strategies, rotation=30, ha=\"right\")\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_title(str(net))\n",
    "        ax.grid(True, axis=\"y\", alpha=0.2)\n",
    "\n",
    "    axes[0].set_ylabel(\"probability mass\")\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc=\"upper right\", ncols=3, frameon=True)\n",
    "    fig.suptitle(f\"AllC / AllD / Not absorbed  {payoff_name}\", y=1.02)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return show_saved(fig, f\"stacked_Pr_allC_allD_active_{payoff_name}.png\")\n",
    "\n",
    "\n",
    "\n",
    "plot_probs_stacked(per_run_df, \"Snowdrift\")\n",
    "plot_probs_stacked(per_run_df, \"Default\")\n",
    "#plot_probs_stacked(per_run_revised, \"Canonical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15597199",
   "metadata": {},
   "source": [
    "## Phase-Transition Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_beta_from_payoff(df, payoff_col=\"payoff\"):\n",
    "    out = df.copy()\n",
    "    out[\"beta\"] = out[payoff_col].str.extract(r\"beta_([0-9.]+)\").astype(float)\n",
    "    return out\n",
    "\n",
    "def summarize_phase(df_runs, strategy_short=\"Imitate\"):\n",
    "    df = df_runs.copy()\n",
    "    df = df[df[\"strategy_short\"] == strategy_short].copy()\n",
    "\n",
    "    df[\"is_allD\"] = (df[\"absorb_state\"] == \"allD\")\n",
    "    df[\"is_allC\"] = (df[\"absorb_state\"] == \"allC\")\n",
    "\n",
    "    rows = []\n",
    "    for (net, beta), g in df.groupby([\"network\", \"beta\"], sort=True):\n",
    "        barC = g[\"barC\"].to_numpy()\n",
    "        n = len(barC)\n",
    "\n",
    "        meanC = float(np.mean(barC))\n",
    "        varC  = float(np.var(barC, ddof=1)) if n > 1 else 0.0\n",
    "\n",
    "        pD = float(np.mean(g[\"is_allD\"]))\n",
    "        pC = float(np.mean(g[\"is_allC\"]))\n",
    "        pNA = 1.0 - pD - pC  # not absorbed\n",
    "\n",
    "        chiD = pD * (1.0 - pD)  # Bernoulli variance proxy; peaks at pD=0.5\n",
    "\n",
    "        rows.append([net, beta, n, meanC, varC, pD, pC, pNA, chiD])\n",
    "\n",
    "    out = pd.DataFrame(rows, columns=[\n",
    "        \"network\",\"beta\",\"n\",\"mean_barC\",\"var_barC\",\"Pr_allD\",\"Pr_allC\",\"Pr_not_absorbed\",\"chiD\"\n",
    "    ]).sort_values([\"network\",\"beta\"])\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3761eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runs = pd.read_csv(\"Results/Result_RQ0/Result_Revised_beta/per_run_revised.csv\")\n",
    "df_runs = add_beta_from_payoff(df_runs)\n",
    "\n",
    "diag = summarize_phase(df_runs, strategy_short=\"Imitate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5dde75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_slopes(diag_one_net):\n",
    "    d = diag_one_net.sort_values(\"beta\").copy()\n",
    "    b = d[\"beta\"].to_numpy()\n",
    "\n",
    "    def slope(y):\n",
    "        y = np.asarray(y)\n",
    "        s = np.diff(y) / (np.diff(b) + 1e-12)\n",
    "        bmid = 0.5*(b[:-1] + b[1:])\n",
    "        return bmid, s\n",
    "\n",
    "    bmid, s_pD = slope(d[\"Pr_allD\"].to_numpy())\n",
    "    _,    s_C  = slope(d[\"mean_barC\"].to_numpy())\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"beta_mid\": bmid,\n",
    "        \"dPr_allD_dbeta\": s_pD,\n",
    "        \"dmeanC_dbeta\": s_C\n",
    "    })\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f84463",
   "metadata": {},
   "outputs": [],
   "source": [
    "for net in diag[\"network\"].unique():\n",
    "    dnet = diag[diag[\"network\"] == net].sort_values(\"beta\")\n",
    "    slopes = add_slopes(dnet)\n",
    "\n",
    "    i = np.abs(slopes[\"dPr_allD_dbeta\"]).idxmax()\n",
    "    beta_star = slopes.loc[i, \"beta_mid\"]\n",
    "    slope_star = slopes.loc[i, \"dPr_allD_dbeta\"]\n",
    "\n",
    "    j = dnet[\"chiD\"].idxmax()\n",
    "    beta_chi = dnet.loc[j, \"beta\"]\n",
    "    chi_star = dnet.loc[j, \"chiD\"]\n",
    "\n",
    "    k = dnet[\"var_barC\"].idxmax()\n",
    "    beta_var = dnet.loc[k, \"beta\"]\n",
    "    var_star = dnet.loc[k, \"var_barC\"]\n",
    "\n",
    "    print(net,\n",
    "          f\"beta*(max |dPr_allD|)={beta_star:.2f}, max slope={slope_star:.3f}\",\n",
    "          f\"beta*(max chiD)={beta_chi:.2f}, chiD={chi_star:.3f}\",\n",
    "          f\"beta*(max varC)={beta_var:.2f}, varC={var_star:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
